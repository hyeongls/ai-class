# ai-class

###  1. 인공지능에서 지능에 해당하는 기술은 무엇인가?
인공지능에서 지능에 해당하는 기술은 사람의 지능을 모방하거나 이를 능가하는 여러 가지 능력을 의미. <br/>
1. 머신러닝 : 데이터를 학습하고, 학습한 결과를 바탕으로 새로운 상황을 예측하거나 결정을 내리는 기술 <br/>
2. 딥러닝 : 인공신경망을 사용하여 데이터를 처리하고, 패턴을 인식하며, 여러 층을 쌓아 복잡한 문제를 해결하는 머신러닝의 하위 분야 <br/>

###  2. 인공지능의 종류 3가지에 대해서 설명하시오(지도학습, 비지도학습, 강화학습)
지도학습 : 레이블이 있는 데이터로 학습  <br/>
반지도학습: 레이블이 없는 데이터로 학습  <br/>
강화학습: 환경과 정책을 세움으로서 보상으로 학습  <br/>

###  3.전통적인 프로그래밍 방법과 인공지능 프로그램의 차이점은 무엇인가?
전통적인 프로그래밍 방법은 명시적은 규칙을 기반으로 문제를 해결하며, 프로그래머가 모든 로직을 직접 정의한다. <br/>
인공지능 프로그램은 데이터를 통해 스스로 학습하여 문제를 해결하며, 복잡한 패턴이나 불확실한 문제를 처리하는데 강점이 있다. <br/>

###  4.딥러닝과 머신러닝의 차이점은 무엇인가?
딥러닝: 모델 내에서 자체적으로 특징을 추출하는 인공지능(특성을 추출해서 넣어주면 성능이 더 좋아지긴 함) <br/>
머신러닝: 특징을 추출해서 모델에 넣어줘야하는 인공지능 <br/>

###  5.Classification과 Regression의 주된 차이점은?
분류: 이산적인 값을 예측하기 위해 사용, 그래프의 구역을 나누기 위해 사용 예) 성별 <br/>
회귀: 연속적인 값을 예측하기 위해 사용, 그래프의 추선을 구하기 위해 사용 예) 온도 <br/>

###  6.머신러닝에서 차원의 저주(curse of dimensionality)란?
차원이 커질수록 계산이 어려워 과적합 확률이 올라감 <br/>
차원의 저주를 해결하기 위해서는 특징의 개수를 줄임(규제 예) n1, n2, scaling) <br/>

###  7.Dimensionality Reduction는 왜 필요한가?
1. 불필요한 변수 저장이나 차원이 많아지면 비례하여 분석시간이 증가하기 때문 <br/>
2. 차원이 높으면 과적합 문제가 발생 <br/>
3. 벡터 간의 거리가 유사하게 되는 문제 발생 <br/>
4. 차원이 높으면 설명력이 떨어짐 <br/>

###  8.Ridge와 Lasso의 공통점과 차이점? (Regularization, 규제 , Scaling)
Ridge는 L2 정규화를 통해 모든 피처의 가중치를 줄이는데 중점을 둔다. <br/>
Lasso는 L1 정규화를 통해 불필요한 피처의 가중치를 0으로 만들어 피처 선택을 수행한다. <br/>

###  9.Overfitting vs. Underfitting
과적합: 과도하게 학습됨. *노이즈, 이상치, 결측치까지 학습을 했을 경우 <br/>
  해결법: 모델 단순화, 데이터 규제 <br/>
과소적합: 데이터 사이의 의존성을 잡아내지 못했을 경우 (모델이 너무 단순한 경우) <br/>
  해결법: 데이터 수 늘려줌 <br/>
  
###  10.Feature Engineering과 Feature Selection의 차이점은?
Feature Engineering은 데이터를 변환하거나 새로운 특성을 만들어내어 모델의 성능을 높이는 과정이다. 이는 원시 데이터를 새로운 정보로 바꾸어, 모델이 더 나은 패턴을 찾도록 도와주는 작업이다. <br/>
Feature Selection은 모델 학습에 가장 유용한 특성을 선택하여 과적합 방지 및 성능을 향상시키는 방법이다. <br/>
=> Feature Engineering은 새로운 특성을 추가하는 과정이고 Feature Selection은 선택된 특성의 수를 감소시키는 방법이다. <br/>

###  11.전처리(Preprocessing)의 목적과 방법? (노이즈, 이상치, 결측치)
전처리는 데이터의 정확성, 일관성 및 완전성을 높여 모델의 성능을 개선하고, 노이즈, 이상치 및 결측치와 같은 문제를 해결하여 일반화 능력을 높이고, 과적합을 방지한다. 또한 데이터의 구조를 단순화하여 이해하기 쉽게 만들어 분석 과정에서의 편리성을 높인다. <br/>

전처리 방법 <br/>
1. 노이즈 처리 <br/>
데이터의 포함된 불필요한 정보나 무작위 변동인 노이즈를 제거하는 방법이다. 방법에는 필터링, 변환, 데이터 집계 등의 방법이 있다. <br/>
2. 이상치 처리 <br/>
다른 데이터와 비교해 비정상적으로 큰 값이나 작은 값인 이상치를 처리하는 방법이다. 이상치 탐지 방법에는 Z-점수, IQR 등을 사용하는 통계적 방법과 박스 플롯이나 산점도를 사용하는 시각화 방법이 있다. <br/>
이상치를 처리하는 방법에는 제거, 변환, Robust 회귀 등의 방법을 사용하여 이상치의 영향을 최소화하는 모델링 방법이 있다. <br/>
3. 결측치 처리 <br/>
특정 데이터 포인트에 대한 값이 없는 경우인 결측치를 처리하는 방법이다. 결측치 처리 방법에는 제거, 대체, 특징 생성 등이 있다. <br/>

###  12.EDA(Explorary Data Analysis)란? 데이터의 특성 파악(분포, 상관관계)
EDA란 데이터 세트를 이해하고, 주요 특성을 파악하며, 데이터의 구조와 패턴을 탐색하는 과정이다. <br/>
EDA 기법에는 히스토그램, 커널 밀도 추정, 박스 플롯 등을 사용하는 데이터 분포 파악 방법과 산점도, 상관계수, 상관행렬을 사용하는 상관관계 분석 방법이 있다. <br/>

###  13.회귀에서 절편과 기울기가 의미하는 바는? 딥러닝과 어떻게 연관되는가?
회귀에서 절편은 독립 변수 x의 값이 0일 때 종속 변수 y의 값으로 특정 독립 변수의 영향을 받지 않을 때의 기본적인 예측값을 의미한다.<br/>
기울기는 독립 변수와 종속 변수 간의 관계의 세기를 나타낸다. 기울기가 양수면 양의 관계, 기울기가 음수면 음의 관계 임을 의미한다. <br/>
딥러닝에서 절편은 바이어스, 기울기는 가중치와 대응된다. <br/>

###  14.Activation function 함수를 사용하는 이유? Softmax, Sigmoid 함수의 차이는?
활성 함수는 인공신경망의 뉴런에서 입력 신호를 출력 신호로 변환하는 역할을 한다. 비선형성을 도입하여 신경망이 복잡한 패턴을 학습할 수 있도록 도와준다. <br/>
Sigmoid 함수의 출력 범위는 0과 1이다. 즉 이진 분류 문제에서 사용되는 함수이다. <br/>
Softmax 함수의 출력 범위는 각 클래스의 확률로 모든 클래스의 합이 1이된다. 즉 다중 클래스 분류 문제에서 사용된다. <br/>

###  15.Forward propagation, Backward propagation이란?
Forward propagation(순전파)란 입력 데이터가 신경망을 통과하여 최종 출력을 생성하는 과정이다. 각 뉴런은 이전 층의 출력과 가중치를 곱하고, 활성화 함수를 적용하여 다음 층으로 정보를 전달한다. <br/>
Backward propagation(역전파)란 손실 함수의 결과를 바탕으로 가중치와 바이어스를 업데이트하는 과정이다. 이 과정은 신경망이 예측을 개선하도록 학습하는 데 필수적이다. <br/>

###  16.손실함수란 무엇인가? 가장 많이 사용하는 손실함수 4가지 종류는?
손실함수란 머신러닝 및 딥러닝 모델의 성능을 평가하는데 사용되는 함수이다. 모델의 예측값과 실제값 간의 차이를 측정하며, 이 값을 최소화하는 방향으로 모델의 가중치를 업데이트하는 데 사용된다. <br/>
손실함수의 종류 <br/>
1. MSE(평균 제곱 오차)
2. MAE(평균 절대 오차)
3. Binary crossentropy(이진 교차 엔트로피)
4. Categorical crossentropy(범주형 교차 엔트로피)

###  17.옵티마이저(optimizer)란 무엇일까? 옵티마이저와 손실함수의 차이점은?
옵티마이저란 모델을 학습하는 과정에서 손실 함수의 값을 최소화하기 위한 가중치와 바이어스를 업데이트하는 알고리즘이다.  <br/>

###  18.경사하강법 의미는? (확률적 경사하강법, 배치 경사하강법, 미치 배치경사하강법)
경사하강법이란 손실 함수를 최소화하기 위해 가중치 및 바이어스를 업데이트하는 최적화 알고리즘이다. 이 알고리즘은 현재 파라미터 지점에서의 손실 함수의 기울기를 계산하여, 손실을 감소시키는 방향으로 파라미터를 조정한다. <br/> <br/>
경사 하강법의 종류 <br/>
1. 배치 경사 하강법 : 전체 데이터셋을 사용하여 기울기를 계산한 후, 가중치를 업데이터하는 방식
   장점 : 각 업데이트가 안정적이며, 전체 데이터에 대한 평균으로 계산되므로 노이즈가 적음<br/>
   단점 : 데이터셋이 클 경우 메모리 소모가 크고, 업데이트가 느려질 수 있음<br/>
2. 확률적 경사 하강법 : 데이터셋에서 임의의 한 샘플을 선택하여 기울기를 계산하고, 가중치를 업데이트하는 방식
   장점 : 각 업데이트가 빠르게 이루어져 메모리 소모가 적고, 보다 자주 가중치를 업데이트할 수 있음 <br/>
   단점 : 업데이트의 분산이 커서 노이즈가 많고, 손실 함수가 요동치는 경향이 있음 <br/>
3. 미니배치 경사 하강법 : 전체 데이터셋을 작은 배치로 나누어 각 배치마다 기울기를 계산하고 가중치를 업데이트하는 방식
   장점 : 배치 경사 하강법과 확률적 경사 하강법의 장점을 결합하여, 안정성과 빠른 수렴 속도를 제공 <br/>
   단점 : 배치 크기를 설정해야 하며, 최적의 배치 크기를 찾는 것이 어려움 <br/>

###  19.교차검증, K-fold 교차검증의 의미와 차이

###  20.하이퍼파라미터 튜닝이란 무엇인가?

###  21.CNN의 합성곱의 역활은?

###  22.CNN의 풀링층의 역활은?

###  23.CNN의 Dense Layer의 역활은?

###  24.CNN의 stride, filter의 역활? 필터의 가중치는 어떻게 결정되는가?

###  25.RNN을 사용하는 이유와 한계점은?

###  26.STM을 사용하는 이유와 한계점은?

###  27.GRU을 사용하는 이유와 차별성은?

###  28.결정트리에서 불순도(Impurity) – 지니 계수(Gini Index)란 무엇인가?

###  29.앙상블이란 무엇인가?

###  30.부트 스트랩핑(bootstraping)이란 무엇인가?

###  31.배깅(Bagging)이란 무엇인가?

###  32.주성분 분석(PCA) 이란 무엇인가?

###  33.Dense Layer란 무엇인가?

#  -------------------------------------------------
#  1주차 정리

##  딥러닝에서 중요한 것

1. lossfunction : 정답과 예측값의 차이를 확인하는 함수 <br/>
2. optimizer : 가중치를 구하는 것 <br/>
3. backpropagation : 최적화를 위해 다시 돌아오며 계산하는 것 <br/>
4. forwardpropagation <br/>
5. activation function : 신경망에 비선형성을 추가하여 특성 추출을 더 많이 할 수 있도록 하는 방법 예) sigmoid, relu <br/><br/>

7. one-hot encodnig : 의미없는 연관성을 끊어주기 위해 사용 <br/>
