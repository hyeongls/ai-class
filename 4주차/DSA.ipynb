{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "85197e5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import StratifiedShuffleSplit\n",
    "from scipy.stats import skew\n",
    "import os\n",
    "import csv\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "45b98db3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>T_xacc_mean</th>\n",
       "      <th>T_xacc_max</th>\n",
       "      <th>T_xacc_min</th>\n",
       "      <th>T_xacc_var</th>\n",
       "      <th>T_xacc_std</th>\n",
       "      <th>T_xacc_skew</th>\n",
       "      <th>T_yacc_mean</th>\n",
       "      <th>T_yacc_max</th>\n",
       "      <th>T_yacc_min</th>\n",
       "      <th>T_yacc_var</th>\n",
       "      <th>...</th>\n",
       "      <th>LL_ymag_std</th>\n",
       "      <th>LL_ymag_skew</th>\n",
       "      <th>LL_zmag_mean</th>\n",
       "      <th>LL_zmag_max</th>\n",
       "      <th>LL_zmag_min</th>\n",
       "      <th>LL_zmag_var</th>\n",
       "      <th>LL_zmag_std</th>\n",
       "      <th>LL_zmag_skew</th>\n",
       "      <th>activity</th>\n",
       "      <th>people</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>7.975714</td>\n",
       "      <td>8.1605</td>\n",
       "      <td>7.6823</td>\n",
       "      <td>0.014395</td>\n",
       "      <td>0.119981</td>\n",
       "      <td>-0.023319</td>\n",
       "      <td>1.083150</td>\n",
       "      <td>1.1832</td>\n",
       "      <td>0.99744</td>\n",
       "      <td>0.002208</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000792</td>\n",
       "      <td>0.177075</td>\n",
       "      <td>-0.057119</td>\n",
       "      <td>-0.054963</td>\n",
       "      <td>-0.059241</td>\n",
       "      <td>6.778722e-07</td>\n",
       "      <td>0.000823</td>\n",
       "      <td>0.036729</td>\n",
       "      <td>sitting</td>\n",
       "      <td>p1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>7.978250</td>\n",
       "      <td>8.1763</td>\n",
       "      <td>7.8472</td>\n",
       "      <td>0.007551</td>\n",
       "      <td>0.086896</td>\n",
       "      <td>0.552416</td>\n",
       "      <td>1.140865</td>\n",
       "      <td>1.2129</td>\n",
       "      <td>1.05810</td>\n",
       "      <td>0.000784</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000860</td>\n",
       "      <td>-0.286918</td>\n",
       "      <td>-0.057268</td>\n",
       "      <td>-0.054945</td>\n",
       "      <td>-0.059589</td>\n",
       "      <td>7.032302e-07</td>\n",
       "      <td>0.000839</td>\n",
       "      <td>0.347471</td>\n",
       "      <td>sitting</td>\n",
       "      <td>p1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>7.970894</td>\n",
       "      <td>8.0860</td>\n",
       "      <td>7.8470</td>\n",
       "      <td>0.003092</td>\n",
       "      <td>0.055603</td>\n",
       "      <td>0.100538</td>\n",
       "      <td>1.140962</td>\n",
       "      <td>1.2128</td>\n",
       "      <td>1.07960</td>\n",
       "      <td>0.000508</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000762</td>\n",
       "      <td>-0.134430</td>\n",
       "      <td>-0.057068</td>\n",
       "      <td>-0.054711</td>\n",
       "      <td>-0.059065</td>\n",
       "      <td>6.268222e-07</td>\n",
       "      <td>0.000792</td>\n",
       "      <td>0.045579</td>\n",
       "      <td>sitting</td>\n",
       "      <td>p1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>7.938412</td>\n",
       "      <td>8.1083</td>\n",
       "      <td>7.6901</td>\n",
       "      <td>0.003763</td>\n",
       "      <td>0.061343</td>\n",
       "      <td>-0.231914</td>\n",
       "      <td>1.165260</td>\n",
       "      <td>1.3170</td>\n",
       "      <td>1.07870</td>\n",
       "      <td>0.002173</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000735</td>\n",
       "      <td>0.021485</td>\n",
       "      <td>-0.056422</td>\n",
       "      <td>-0.053670</td>\n",
       "      <td>-0.058310</td>\n",
       "      <td>8.011245e-07</td>\n",
       "      <td>0.000895</td>\n",
       "      <td>0.240690</td>\n",
       "      <td>sitting</td>\n",
       "      <td>p1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7.908930</td>\n",
       "      <td>8.1305</td>\n",
       "      <td>7.8322</td>\n",
       "      <td>0.001741</td>\n",
       "      <td>0.041731</td>\n",
       "      <td>2.042285</td>\n",
       "      <td>1.187504</td>\n",
       "      <td>1.2574</td>\n",
       "      <td>1.09450</td>\n",
       "      <td>0.000662</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000824</td>\n",
       "      <td>-0.148229</td>\n",
       "      <td>-0.055801</td>\n",
       "      <td>-0.053313</td>\n",
       "      <td>-0.057815</td>\n",
       "      <td>6.853423e-07</td>\n",
       "      <td>0.000828</td>\n",
       "      <td>0.258429</td>\n",
       "      <td>sitting</td>\n",
       "      <td>p1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9115</th>\n",
       "      <td>8.280854</td>\n",
       "      <td>34.1980</td>\n",
       "      <td>-2.9038</td>\n",
       "      <td>28.080803</td>\n",
       "      <td>5.299132</td>\n",
       "      <td>1.350075</td>\n",
       "      <td>-1.491537</td>\n",
       "      <td>11.2240</td>\n",
       "      <td>-11.65100</td>\n",
       "      <td>14.670334</td>\n",
       "      <td>...</td>\n",
       "      <td>0.200829</td>\n",
       "      <td>-0.040701</td>\n",
       "      <td>0.297666</td>\n",
       "      <td>0.708480</td>\n",
       "      <td>-0.117430</td>\n",
       "      <td>4.135451e-02</td>\n",
       "      <td>0.203358</td>\n",
       "      <td>-0.310022</td>\n",
       "      <td>basketBall</td>\n",
       "      <td>p8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9116</th>\n",
       "      <td>9.591118</td>\n",
       "      <td>51.6970</td>\n",
       "      <td>-3.4129</td>\n",
       "      <td>35.722025</td>\n",
       "      <td>5.976791</td>\n",
       "      <td>2.981144</td>\n",
       "      <td>0.086304</td>\n",
       "      <td>6.9951</td>\n",
       "      <td>-11.76400</td>\n",
       "      <td>5.329897</td>\n",
       "      <td>...</td>\n",
       "      <td>0.148745</td>\n",
       "      <td>-0.266377</td>\n",
       "      <td>0.224716</td>\n",
       "      <td>0.554670</td>\n",
       "      <td>-0.250950</td>\n",
       "      <td>3.355704e-02</td>\n",
       "      <td>0.183186</td>\n",
       "      <td>-0.736410</td>\n",
       "      <td>basketBall</td>\n",
       "      <td>p8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9117</th>\n",
       "      <td>9.599113</td>\n",
       "      <td>27.9300</td>\n",
       "      <td>-1.0765</td>\n",
       "      <td>48.850886</td>\n",
       "      <td>6.989341</td>\n",
       "      <td>0.449237</td>\n",
       "      <td>-0.728367</td>\n",
       "      <td>3.7801</td>\n",
       "      <td>-8.36910</td>\n",
       "      <td>5.683022</td>\n",
       "      <td>...</td>\n",
       "      <td>0.310748</td>\n",
       "      <td>-0.009505</td>\n",
       "      <td>-0.237786</td>\n",
       "      <td>0.088854</td>\n",
       "      <td>-0.477260</td>\n",
       "      <td>2.026107e-02</td>\n",
       "      <td>0.142341</td>\n",
       "      <td>0.668438</td>\n",
       "      <td>basketBall</td>\n",
       "      <td>p8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9118</th>\n",
       "      <td>9.692482</td>\n",
       "      <td>72.7820</td>\n",
       "      <td>-2.6734</td>\n",
       "      <td>59.378336</td>\n",
       "      <td>7.705734</td>\n",
       "      <td>4.491114</td>\n",
       "      <td>-0.582724</td>\n",
       "      <td>6.1216</td>\n",
       "      <td>-8.85710</td>\n",
       "      <td>4.162963</td>\n",
       "      <td>...</td>\n",
       "      <td>0.156493</td>\n",
       "      <td>0.050624</td>\n",
       "      <td>0.533023</td>\n",
       "      <td>0.677800</td>\n",
       "      <td>0.055941</td>\n",
       "      <td>1.356379e-02</td>\n",
       "      <td>0.116464</td>\n",
       "      <td>-1.482489</td>\n",
       "      <td>basketBall</td>\n",
       "      <td>p8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9119</th>\n",
       "      <td>9.380641</td>\n",
       "      <td>45.0090</td>\n",
       "      <td>-3.5938</td>\n",
       "      <td>40.459334</td>\n",
       "      <td>6.360765</td>\n",
       "      <td>1.688626</td>\n",
       "      <td>-0.266325</td>\n",
       "      <td>5.8603</td>\n",
       "      <td>-6.91970</td>\n",
       "      <td>4.017098</td>\n",
       "      <td>...</td>\n",
       "      <td>0.229154</td>\n",
       "      <td>-0.342228</td>\n",
       "      <td>0.491919</td>\n",
       "      <td>0.707920</td>\n",
       "      <td>0.251280</td>\n",
       "      <td>9.358254e-03</td>\n",
       "      <td>0.096738</td>\n",
       "      <td>-0.223302</td>\n",
       "      <td>basketBall</td>\n",
       "      <td>p8</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>9120 rows × 272 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      T_xacc_mean  T_xacc_max  T_xacc_min  T_xacc_var  T_xacc_std  \\\n",
       "0        7.975714      8.1605      7.6823    0.014395    0.119981   \n",
       "1        7.978250      8.1763      7.8472    0.007551    0.086896   \n",
       "2        7.970894      8.0860      7.8470    0.003092    0.055603   \n",
       "3        7.938412      8.1083      7.6901    0.003763    0.061343   \n",
       "4        7.908930      8.1305      7.8322    0.001741    0.041731   \n",
       "...           ...         ...         ...         ...         ...   \n",
       "9115     8.280854     34.1980     -2.9038   28.080803    5.299132   \n",
       "9116     9.591118     51.6970     -3.4129   35.722025    5.976791   \n",
       "9117     9.599113     27.9300     -1.0765   48.850886    6.989341   \n",
       "9118     9.692482     72.7820     -2.6734   59.378336    7.705734   \n",
       "9119     9.380641     45.0090     -3.5938   40.459334    6.360765   \n",
       "\n",
       "      T_xacc_skew  T_yacc_mean  T_yacc_max  T_yacc_min  T_yacc_var  ...  \\\n",
       "0       -0.023319     1.083150      1.1832     0.99744    0.002208  ...   \n",
       "1        0.552416     1.140865      1.2129     1.05810    0.000784  ...   \n",
       "2        0.100538     1.140962      1.2128     1.07960    0.000508  ...   \n",
       "3       -0.231914     1.165260      1.3170     1.07870    0.002173  ...   \n",
       "4        2.042285     1.187504      1.2574     1.09450    0.000662  ...   \n",
       "...           ...          ...         ...         ...         ...  ...   \n",
       "9115     1.350075    -1.491537     11.2240   -11.65100   14.670334  ...   \n",
       "9116     2.981144     0.086304      6.9951   -11.76400    5.329897  ...   \n",
       "9117     0.449237    -0.728367      3.7801    -8.36910    5.683022  ...   \n",
       "9118     4.491114    -0.582724      6.1216    -8.85710    4.162963  ...   \n",
       "9119     1.688626    -0.266325      5.8603    -6.91970    4.017098  ...   \n",
       "\n",
       "      LL_ymag_std  LL_ymag_skew  LL_zmag_mean  LL_zmag_max  LL_zmag_min  \\\n",
       "0        0.000792      0.177075     -0.057119    -0.054963    -0.059241   \n",
       "1        0.000860     -0.286918     -0.057268    -0.054945    -0.059589   \n",
       "2        0.000762     -0.134430     -0.057068    -0.054711    -0.059065   \n",
       "3        0.000735      0.021485     -0.056422    -0.053670    -0.058310   \n",
       "4        0.000824     -0.148229     -0.055801    -0.053313    -0.057815   \n",
       "...           ...           ...           ...          ...          ...   \n",
       "9115     0.200829     -0.040701      0.297666     0.708480    -0.117430   \n",
       "9116     0.148745     -0.266377      0.224716     0.554670    -0.250950   \n",
       "9117     0.310748     -0.009505     -0.237786     0.088854    -0.477260   \n",
       "9118     0.156493      0.050624      0.533023     0.677800     0.055941   \n",
       "9119     0.229154     -0.342228      0.491919     0.707920     0.251280   \n",
       "\n",
       "       LL_zmag_var  LL_zmag_std  LL_zmag_skew    activity  people  \n",
       "0     6.778722e-07     0.000823      0.036729     sitting      p1  \n",
       "1     7.032302e-07     0.000839      0.347471     sitting      p1  \n",
       "2     6.268222e-07     0.000792      0.045579     sitting      p1  \n",
       "3     8.011245e-07     0.000895      0.240690     sitting      p1  \n",
       "4     6.853423e-07     0.000828      0.258429     sitting      p1  \n",
       "...            ...          ...           ...         ...     ...  \n",
       "9115  4.135451e-02     0.203358     -0.310022  basketBall      p8  \n",
       "9116  3.355704e-02     0.183186     -0.736410  basketBall      p8  \n",
       "9117  2.026107e-02     0.142341      0.668438  basketBall      p8  \n",
       "9118  1.356379e-02     0.116464     -1.482489  basketBall      p8  \n",
       "9119  9.358254e-03     0.096738     -0.223302  basketBall      p8  \n",
       "\n",
       "[9120 rows x 272 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"C:\\datasets/DSA_features.csv\")\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cd57f557",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_RA = df.filter(regex='RA_') \n",
    "df_LA = df.filter(regex='LA_') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3a72ecb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_RA.insert(3, 'activity', df['activity'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "065154d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_LA.insert(3, 'activity', df['activity'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7e24c10a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>RA_xacc_mean</th>\n",
       "      <th>RA_xacc_max</th>\n",
       "      <th>RA_xacc_min</th>\n",
       "      <th>activity</th>\n",
       "      <th>RA_xacc_var</th>\n",
       "      <th>RA_xacc_std</th>\n",
       "      <th>RA_xacc_skew</th>\n",
       "      <th>RA_yacc_mean</th>\n",
       "      <th>RA_yacc_max</th>\n",
       "      <th>RA_yacc_min</th>\n",
       "      <th>...</th>\n",
       "      <th>RA_ymag_min</th>\n",
       "      <th>RA_ymag_var</th>\n",
       "      <th>RA_ymag_std</th>\n",
       "      <th>RA_ymag_skew</th>\n",
       "      <th>RA_zmag_mean</th>\n",
       "      <th>RA_zmag_max</th>\n",
       "      <th>RA_zmag_min</th>\n",
       "      <th>RA_zmag_var</th>\n",
       "      <th>RA_zmag_std</th>\n",
       "      <th>RA_zmag_skew</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.679134</td>\n",
       "      <td>0.75930</td>\n",
       "      <td>0.58542</td>\n",
       "      <td>sitting</td>\n",
       "      <td>0.001546</td>\n",
       "      <td>0.039324</td>\n",
       "      <td>-0.415694</td>\n",
       "      <td>5.713088</td>\n",
       "      <td>5.8483</td>\n",
       "      <td>5.5956</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.57428</td>\n",
       "      <td>0.000012</td>\n",
       "      <td>0.003401</td>\n",
       "      <td>-0.052190</td>\n",
       "      <td>-0.211136</td>\n",
       "      <td>-0.18401</td>\n",
       "      <td>-0.24523</td>\n",
       "      <td>0.000044</td>\n",
       "      <td>0.006638</td>\n",
       "      <td>-1.153902</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.644964</td>\n",
       "      <td>0.73158</td>\n",
       "      <td>0.53064</td>\n",
       "      <td>sitting</td>\n",
       "      <td>0.001333</td>\n",
       "      <td>0.036508</td>\n",
       "      <td>0.410625</td>\n",
       "      <td>5.795154</td>\n",
       "      <td>5.9546</td>\n",
       "      <td>5.6687</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.57398</td>\n",
       "      <td>0.000005</td>\n",
       "      <td>0.002216</td>\n",
       "      <td>0.222740</td>\n",
       "      <td>-0.206431</td>\n",
       "      <td>-0.18054</td>\n",
       "      <td>-0.23624</td>\n",
       "      <td>0.000032</td>\n",
       "      <td>0.005660</td>\n",
       "      <td>0.458427</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.608212</td>\n",
       "      <td>0.67737</td>\n",
       "      <td>0.53546</td>\n",
       "      <td>sitting</td>\n",
       "      <td>0.000637</td>\n",
       "      <td>0.025244</td>\n",
       "      <td>0.153302</td>\n",
       "      <td>5.833086</td>\n",
       "      <td>5.8918</td>\n",
       "      <td>5.7656</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.57563</td>\n",
       "      <td>0.000004</td>\n",
       "      <td>0.001954</td>\n",
       "      <td>-0.221765</td>\n",
       "      <td>-0.205648</td>\n",
       "      <td>-0.18342</td>\n",
       "      <td>-0.22933</td>\n",
       "      <td>0.000024</td>\n",
       "      <td>0.004868</td>\n",
       "      <td>-0.984915</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.591138</td>\n",
       "      <td>0.71177</td>\n",
       "      <td>0.51524</td>\n",
       "      <td>sitting</td>\n",
       "      <td>0.001349</td>\n",
       "      <td>0.036731</td>\n",
       "      <td>0.525019</td>\n",
       "      <td>5.863846</td>\n",
       "      <td>5.9645</td>\n",
       "      <td>5.7556</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.57858</td>\n",
       "      <td>0.000007</td>\n",
       "      <td>0.002688</td>\n",
       "      <td>0.075011</td>\n",
       "      <td>-0.203739</td>\n",
       "      <td>-0.17999</td>\n",
       "      <td>-0.22958</td>\n",
       "      <td>0.000026</td>\n",
       "      <td>0.005099</td>\n",
       "      <td>0.185634</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.558168</td>\n",
       "      <td>0.67190</td>\n",
       "      <td>0.50535</td>\n",
       "      <td>sitting</td>\n",
       "      <td>0.000626</td>\n",
       "      <td>0.025020</td>\n",
       "      <td>1.076782</td>\n",
       "      <td>5.884745</td>\n",
       "      <td>5.9401</td>\n",
       "      <td>5.8384</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.57996</td>\n",
       "      <td>0.000005</td>\n",
       "      <td>0.002278</td>\n",
       "      <td>-0.219440</td>\n",
       "      <td>-0.203684</td>\n",
       "      <td>-0.17904</td>\n",
       "      <td>-0.22924</td>\n",
       "      <td>0.000027</td>\n",
       "      <td>0.005175</td>\n",
       "      <td>-0.820907</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9115</th>\n",
       "      <td>8.690373</td>\n",
       "      <td>30.46300</td>\n",
       "      <td>-4.90150</td>\n",
       "      <td>basketBall</td>\n",
       "      <td>47.192912</td>\n",
       "      <td>6.869710</td>\n",
       "      <td>0.650080</td>\n",
       "      <td>2.187710</td>\n",
       "      <td>41.3410</td>\n",
       "      <td>-10.1410</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.89670</td>\n",
       "      <td>0.177217</td>\n",
       "      <td>0.420971</td>\n",
       "      <td>1.232819</td>\n",
       "      <td>-0.120793</td>\n",
       "      <td>0.58641</td>\n",
       "      <td>-0.61373</td>\n",
       "      <td>0.077901</td>\n",
       "      <td>0.279107</td>\n",
       "      <td>0.611462</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9116</th>\n",
       "      <td>6.477090</td>\n",
       "      <td>48.54700</td>\n",
       "      <td>-9.96820</td>\n",
       "      <td>basketBall</td>\n",
       "      <td>44.135927</td>\n",
       "      <td>6.643488</td>\n",
       "      <td>1.675812</td>\n",
       "      <td>5.845459</td>\n",
       "      <td>33.7910</td>\n",
       "      <td>-48.3200</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.85305</td>\n",
       "      <td>0.158099</td>\n",
       "      <td>0.397617</td>\n",
       "      <td>1.560701</td>\n",
       "      <td>-0.133269</td>\n",
       "      <td>0.51707</td>\n",
       "      <td>-0.52776</td>\n",
       "      <td>0.058400</td>\n",
       "      <td>0.241661</td>\n",
       "      <td>0.574120</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9117</th>\n",
       "      <td>6.309986</td>\n",
       "      <td>27.29900</td>\n",
       "      <td>-8.43140</td>\n",
       "      <td>basketBall</td>\n",
       "      <td>57.018917</td>\n",
       "      <td>7.551087</td>\n",
       "      <td>0.108921</td>\n",
       "      <td>6.342772</td>\n",
       "      <td>27.0570</td>\n",
       "      <td>-6.6706</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.83512</td>\n",
       "      <td>0.126188</td>\n",
       "      <td>0.355229</td>\n",
       "      <td>1.598340</td>\n",
       "      <td>-0.567238</td>\n",
       "      <td>-0.14483</td>\n",
       "      <td>-0.82409</td>\n",
       "      <td>0.023408</td>\n",
       "      <td>0.152998</td>\n",
       "      <td>0.598665</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9118</th>\n",
       "      <td>5.020496</td>\n",
       "      <td>30.16600</td>\n",
       "      <td>-20.25100</td>\n",
       "      <td>basketBall</td>\n",
       "      <td>67.001032</td>\n",
       "      <td>8.185416</td>\n",
       "      <td>0.157547</td>\n",
       "      <td>5.824265</td>\n",
       "      <td>27.6300</td>\n",
       "      <td>-19.8830</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.87361</td>\n",
       "      <td>0.174494</td>\n",
       "      <td>0.417725</td>\n",
       "      <td>0.758435</td>\n",
       "      <td>0.211566</td>\n",
       "      <td>0.67931</td>\n",
       "      <td>-0.22328</td>\n",
       "      <td>0.060114</td>\n",
       "      <td>0.245181</td>\n",
       "      <td>0.316989</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9119</th>\n",
       "      <td>4.293377</td>\n",
       "      <td>31.57000</td>\n",
       "      <td>-22.85700</td>\n",
       "      <td>basketBall</td>\n",
       "      <td>105.947639</td>\n",
       "      <td>10.293087</td>\n",
       "      <td>0.223835</td>\n",
       "      <td>5.504619</td>\n",
       "      <td>27.3490</td>\n",
       "      <td>-13.7600</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.88818</td>\n",
       "      <td>0.144466</td>\n",
       "      <td>0.380087</td>\n",
       "      <td>0.359933</td>\n",
       "      <td>0.146602</td>\n",
       "      <td>0.62601</td>\n",
       "      <td>-0.28631</td>\n",
       "      <td>0.055074</td>\n",
       "      <td>0.234679</td>\n",
       "      <td>0.123701</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>9120 rows × 55 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      RA_xacc_mean  RA_xacc_max  RA_xacc_min    activity  RA_xacc_var  \\\n",
       "0         0.679134      0.75930      0.58542     sitting     0.001546   \n",
       "1         0.644964      0.73158      0.53064     sitting     0.001333   \n",
       "2         0.608212      0.67737      0.53546     sitting     0.000637   \n",
       "3         0.591138      0.71177      0.51524     sitting     0.001349   \n",
       "4         0.558168      0.67190      0.50535     sitting     0.000626   \n",
       "...            ...          ...          ...         ...          ...   \n",
       "9115      8.690373     30.46300     -4.90150  basketBall    47.192912   \n",
       "9116      6.477090     48.54700     -9.96820  basketBall    44.135927   \n",
       "9117      6.309986     27.29900     -8.43140  basketBall    57.018917   \n",
       "9118      5.020496     30.16600    -20.25100  basketBall    67.001032   \n",
       "9119      4.293377     31.57000    -22.85700  basketBall   105.947639   \n",
       "\n",
       "      RA_xacc_std  RA_xacc_skew  RA_yacc_mean  RA_yacc_max  RA_yacc_min  ...  \\\n",
       "0        0.039324     -0.415694      5.713088       5.8483       5.5956  ...   \n",
       "1        0.036508      0.410625      5.795154       5.9546       5.6687  ...   \n",
       "2        0.025244      0.153302      5.833086       5.8918       5.7656  ...   \n",
       "3        0.036731      0.525019      5.863846       5.9645       5.7556  ...   \n",
       "4        0.025020      1.076782      5.884745       5.9401       5.8384  ...   \n",
       "...           ...           ...           ...          ...          ...  ...   \n",
       "9115     6.869710      0.650080      2.187710      41.3410     -10.1410  ...   \n",
       "9116     6.643488      1.675812      5.845459      33.7910     -48.3200  ...   \n",
       "9117     7.551087      0.108921      6.342772      27.0570      -6.6706  ...   \n",
       "9118     8.185416      0.157547      5.824265      27.6300     -19.8830  ...   \n",
       "9119    10.293087      0.223835      5.504619      27.3490     -13.7600  ...   \n",
       "\n",
       "      RA_ymag_min  RA_ymag_var  RA_ymag_std  RA_ymag_skew  RA_zmag_mean  \\\n",
       "0        -0.57428     0.000012     0.003401     -0.052190     -0.211136   \n",
       "1        -0.57398     0.000005     0.002216      0.222740     -0.206431   \n",
       "2        -0.57563     0.000004     0.001954     -0.221765     -0.205648   \n",
       "3        -0.57858     0.000007     0.002688      0.075011     -0.203739   \n",
       "4        -0.57996     0.000005     0.002278     -0.219440     -0.203684   \n",
       "...           ...          ...          ...           ...           ...   \n",
       "9115     -0.89670     0.177217     0.420971      1.232819     -0.120793   \n",
       "9116     -0.85305     0.158099     0.397617      1.560701     -0.133269   \n",
       "9117     -0.83512     0.126188     0.355229      1.598340     -0.567238   \n",
       "9118     -0.87361     0.174494     0.417725      0.758435      0.211566   \n",
       "9119     -0.88818     0.144466     0.380087      0.359933      0.146602   \n",
       "\n",
       "      RA_zmag_max  RA_zmag_min  RA_zmag_var  RA_zmag_std  RA_zmag_skew  \n",
       "0        -0.18401     -0.24523     0.000044     0.006638     -1.153902  \n",
       "1        -0.18054     -0.23624     0.000032     0.005660      0.458427  \n",
       "2        -0.18342     -0.22933     0.000024     0.004868     -0.984915  \n",
       "3        -0.17999     -0.22958     0.000026     0.005099      0.185634  \n",
       "4        -0.17904     -0.22924     0.000027     0.005175     -0.820907  \n",
       "...           ...          ...          ...          ...           ...  \n",
       "9115      0.58641     -0.61373     0.077901     0.279107      0.611462  \n",
       "9116      0.51707     -0.52776     0.058400     0.241661      0.574120  \n",
       "9117     -0.14483     -0.82409     0.023408     0.152998      0.598665  \n",
       "9118      0.67931     -0.22328     0.060114     0.245181      0.316989  \n",
       "9119      0.62601     -0.28631     0.055074     0.234679      0.123701  \n",
       "\n",
       "[9120 rows x 55 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_RA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b6222e25",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>LA_xacc_mean</th>\n",
       "      <th>LA_xacc_max</th>\n",
       "      <th>LA_xacc_min</th>\n",
       "      <th>activity</th>\n",
       "      <th>LA_xacc_var</th>\n",
       "      <th>LA_xacc_std</th>\n",
       "      <th>LA_xacc_skew</th>\n",
       "      <th>LA_yacc_mean</th>\n",
       "      <th>LA_yacc_max</th>\n",
       "      <th>LA_yacc_min</th>\n",
       "      <th>...</th>\n",
       "      <th>LA_ymag_min</th>\n",
       "      <th>LA_ymag_var</th>\n",
       "      <th>LA_ymag_std</th>\n",
       "      <th>LA_ymag_skew</th>\n",
       "      <th>LA_zmag_mean</th>\n",
       "      <th>LA_zmag_max</th>\n",
       "      <th>LA_zmag_min</th>\n",
       "      <th>LA_zmag_var</th>\n",
       "      <th>LA_zmag_std</th>\n",
       "      <th>LA_zmag_skew</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3.403317</td>\n",
       "      <td>3.4875</td>\n",
       "      <td>3.2682</td>\n",
       "      <td>sitting</td>\n",
       "      <td>0.001583</td>\n",
       "      <td>0.039790</td>\n",
       "      <td>-0.744647</td>\n",
       "      <td>-8.375713</td>\n",
       "      <td>-8.2927</td>\n",
       "      <td>-8.4821</td>\n",
       "      <td>...</td>\n",
       "      <td>0.33748</td>\n",
       "      <td>0.000003</td>\n",
       "      <td>0.001810</td>\n",
       "      <td>-0.215069</td>\n",
       "      <td>0.072273</td>\n",
       "      <td>0.076374</td>\n",
       "      <td>0.067940</td>\n",
       "      <td>0.000004</td>\n",
       "      <td>0.001910</td>\n",
       "      <td>-0.166015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3.427302</td>\n",
       "      <td>3.6630</td>\n",
       "      <td>3.3168</td>\n",
       "      <td>sitting</td>\n",
       "      <td>0.004305</td>\n",
       "      <td>0.065614</td>\n",
       "      <td>1.000107</td>\n",
       "      <td>-8.397591</td>\n",
       "      <td>-8.3118</td>\n",
       "      <td>-8.5017</td>\n",
       "      <td>...</td>\n",
       "      <td>0.33000</td>\n",
       "      <td>0.000017</td>\n",
       "      <td>0.004159</td>\n",
       "      <td>-0.611251</td>\n",
       "      <td>0.074557</td>\n",
       "      <td>0.085184</td>\n",
       "      <td>0.068169</td>\n",
       "      <td>0.000022</td>\n",
       "      <td>0.004643</td>\n",
       "      <td>0.717286</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3.400870</td>\n",
       "      <td>3.5168</td>\n",
       "      <td>3.3315</td>\n",
       "      <td>sitting</td>\n",
       "      <td>0.001007</td>\n",
       "      <td>0.031732</td>\n",
       "      <td>0.978319</td>\n",
       "      <td>-8.439138</td>\n",
       "      <td>-8.3599</td>\n",
       "      <td>-8.5204</td>\n",
       "      <td>...</td>\n",
       "      <td>0.33307</td>\n",
       "      <td>0.000002</td>\n",
       "      <td>0.001316</td>\n",
       "      <td>-0.506255</td>\n",
       "      <td>0.075852</td>\n",
       "      <td>0.083227</td>\n",
       "      <td>0.072507</td>\n",
       "      <td>0.000004</td>\n",
       "      <td>0.002106</td>\n",
       "      <td>1.043919</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3.391002</td>\n",
       "      <td>3.5311</td>\n",
       "      <td>3.2608</td>\n",
       "      <td>sitting</td>\n",
       "      <td>0.001792</td>\n",
       "      <td>0.042328</td>\n",
       "      <td>0.117935</td>\n",
       "      <td>-8.441421</td>\n",
       "      <td>-8.3207</td>\n",
       "      <td>-8.5446</td>\n",
       "      <td>...</td>\n",
       "      <td>0.33431</td>\n",
       "      <td>0.000002</td>\n",
       "      <td>0.001395</td>\n",
       "      <td>0.155251</td>\n",
       "      <td>0.074878</td>\n",
       "      <td>0.080059</td>\n",
       "      <td>0.069942</td>\n",
       "      <td>0.000006</td>\n",
       "      <td>0.002414</td>\n",
       "      <td>0.242524</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3.359974</td>\n",
       "      <td>3.4434</td>\n",
       "      <td>3.3069</td>\n",
       "      <td>sitting</td>\n",
       "      <td>0.000633</td>\n",
       "      <td>0.025160</td>\n",
       "      <td>1.051627</td>\n",
       "      <td>-8.454854</td>\n",
       "      <td>-8.3202</td>\n",
       "      <td>-8.5561</td>\n",
       "      <td>...</td>\n",
       "      <td>0.33631</td>\n",
       "      <td>0.000001</td>\n",
       "      <td>0.001005</td>\n",
       "      <td>-0.299017</td>\n",
       "      <td>0.073398</td>\n",
       "      <td>0.077461</td>\n",
       "      <td>0.070175</td>\n",
       "      <td>0.000002</td>\n",
       "      <td>0.001482</td>\n",
       "      <td>0.606258</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9115</th>\n",
       "      <td>8.834459</td>\n",
       "      <td>40.1640</td>\n",
       "      <td>-15.3980</td>\n",
       "      <td>basketBall</td>\n",
       "      <td>140.063928</td>\n",
       "      <td>11.834861</td>\n",
       "      <td>0.486128</td>\n",
       "      <td>-3.441297</td>\n",
       "      <td>39.7590</td>\n",
       "      <td>-53.6520</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.87575</td>\n",
       "      <td>0.210911</td>\n",
       "      <td>0.459250</td>\n",
       "      <td>-0.421162</td>\n",
       "      <td>-0.529403</td>\n",
       "      <td>0.653000</td>\n",
       "      <td>-0.879310</td>\n",
       "      <td>0.123917</td>\n",
       "      <td>0.352018</td>\n",
       "      <td>1.813520</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9116</th>\n",
       "      <td>6.647402</td>\n",
       "      <td>43.9160</td>\n",
       "      <td>-22.3060</td>\n",
       "      <td>basketBall</td>\n",
       "      <td>65.655140</td>\n",
       "      <td>8.102786</td>\n",
       "      <td>0.067916</td>\n",
       "      <td>-5.140474</td>\n",
       "      <td>26.7770</td>\n",
       "      <td>-41.9160</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.77618</td>\n",
       "      <td>0.143162</td>\n",
       "      <td>0.378368</td>\n",
       "      <td>-1.307983</td>\n",
       "      <td>-0.466066</td>\n",
       "      <td>0.659650</td>\n",
       "      <td>-0.835960</td>\n",
       "      <td>0.167255</td>\n",
       "      <td>0.408968</td>\n",
       "      <td>1.483683</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9117</th>\n",
       "      <td>3.108810</td>\n",
       "      <td>40.2770</td>\n",
       "      <td>-10.9500</td>\n",
       "      <td>basketBall</td>\n",
       "      <td>84.701543</td>\n",
       "      <td>9.203344</td>\n",
       "      <td>1.178224</td>\n",
       "      <td>-4.881662</td>\n",
       "      <td>43.4020</td>\n",
       "      <td>-27.3490</td>\n",
       "      <td>...</td>\n",
       "      <td>0.16648</td>\n",
       "      <td>0.035696</td>\n",
       "      <td>0.188933</td>\n",
       "      <td>-0.736037</td>\n",
       "      <td>-0.286489</td>\n",
       "      <td>0.632420</td>\n",
       "      <td>-0.837640</td>\n",
       "      <td>0.109532</td>\n",
       "      <td>0.330956</td>\n",
       "      <td>0.502392</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9118</th>\n",
       "      <td>5.141190</td>\n",
       "      <td>68.5920</td>\n",
       "      <td>-43.1120</td>\n",
       "      <td>basketBall</td>\n",
       "      <td>137.860050</td>\n",
       "      <td>11.741382</td>\n",
       "      <td>1.219670</td>\n",
       "      <td>-3.365847</td>\n",
       "      <td>23.6960</td>\n",
       "      <td>-34.5820</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.85130</td>\n",
       "      <td>0.205452</td>\n",
       "      <td>0.453268</td>\n",
       "      <td>0.171353</td>\n",
       "      <td>-0.567578</td>\n",
       "      <td>0.264780</td>\n",
       "      <td>-0.854420</td>\n",
       "      <td>0.059971</td>\n",
       "      <td>0.244890</td>\n",
       "      <td>1.467799</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9119</th>\n",
       "      <td>3.479606</td>\n",
       "      <td>65.9370</td>\n",
       "      <td>-36.2990</td>\n",
       "      <td>basketBall</td>\n",
       "      <td>181.700701</td>\n",
       "      <td>13.479640</td>\n",
       "      <td>1.245403</td>\n",
       "      <td>-3.535975</td>\n",
       "      <td>43.4110</td>\n",
       "      <td>-28.5330</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.84444</td>\n",
       "      <td>0.273957</td>\n",
       "      <td>0.523409</td>\n",
       "      <td>0.275649</td>\n",
       "      <td>-0.415991</td>\n",
       "      <td>0.267410</td>\n",
       "      <td>-0.849240</td>\n",
       "      <td>0.076105</td>\n",
       "      <td>0.275871</td>\n",
       "      <td>0.349721</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>9120 rows × 55 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      LA_xacc_mean  LA_xacc_max  LA_xacc_min    activity  LA_xacc_var  \\\n",
       "0         3.403317       3.4875       3.2682     sitting     0.001583   \n",
       "1         3.427302       3.6630       3.3168     sitting     0.004305   \n",
       "2         3.400870       3.5168       3.3315     sitting     0.001007   \n",
       "3         3.391002       3.5311       3.2608     sitting     0.001792   \n",
       "4         3.359974       3.4434       3.3069     sitting     0.000633   \n",
       "...            ...          ...          ...         ...          ...   \n",
       "9115      8.834459      40.1640     -15.3980  basketBall   140.063928   \n",
       "9116      6.647402      43.9160     -22.3060  basketBall    65.655140   \n",
       "9117      3.108810      40.2770     -10.9500  basketBall    84.701543   \n",
       "9118      5.141190      68.5920     -43.1120  basketBall   137.860050   \n",
       "9119      3.479606      65.9370     -36.2990  basketBall   181.700701   \n",
       "\n",
       "      LA_xacc_std  LA_xacc_skew  LA_yacc_mean  LA_yacc_max  LA_yacc_min  ...  \\\n",
       "0        0.039790     -0.744647     -8.375713      -8.2927      -8.4821  ...   \n",
       "1        0.065614      1.000107     -8.397591      -8.3118      -8.5017  ...   \n",
       "2        0.031732      0.978319     -8.439138      -8.3599      -8.5204  ...   \n",
       "3        0.042328      0.117935     -8.441421      -8.3207      -8.5446  ...   \n",
       "4        0.025160      1.051627     -8.454854      -8.3202      -8.5561  ...   \n",
       "...           ...           ...           ...          ...          ...  ...   \n",
       "9115    11.834861      0.486128     -3.441297      39.7590     -53.6520  ...   \n",
       "9116     8.102786      0.067916     -5.140474      26.7770     -41.9160  ...   \n",
       "9117     9.203344      1.178224     -4.881662      43.4020     -27.3490  ...   \n",
       "9118    11.741382      1.219670     -3.365847      23.6960     -34.5820  ...   \n",
       "9119    13.479640      1.245403     -3.535975      43.4110     -28.5330  ...   \n",
       "\n",
       "      LA_ymag_min  LA_ymag_var  LA_ymag_std  LA_ymag_skew  LA_zmag_mean  \\\n",
       "0         0.33748     0.000003     0.001810     -0.215069      0.072273   \n",
       "1         0.33000     0.000017     0.004159     -0.611251      0.074557   \n",
       "2         0.33307     0.000002     0.001316     -0.506255      0.075852   \n",
       "3         0.33431     0.000002     0.001395      0.155251      0.074878   \n",
       "4         0.33631     0.000001     0.001005     -0.299017      0.073398   \n",
       "...           ...          ...          ...           ...           ...   \n",
       "9115     -0.87575     0.210911     0.459250     -0.421162     -0.529403   \n",
       "9116     -0.77618     0.143162     0.378368     -1.307983     -0.466066   \n",
       "9117      0.16648     0.035696     0.188933     -0.736037     -0.286489   \n",
       "9118     -0.85130     0.205452     0.453268      0.171353     -0.567578   \n",
       "9119     -0.84444     0.273957     0.523409      0.275649     -0.415991   \n",
       "\n",
       "      LA_zmag_max  LA_zmag_min  LA_zmag_var  LA_zmag_std  LA_zmag_skew  \n",
       "0        0.076374     0.067940     0.000004     0.001910     -0.166015  \n",
       "1        0.085184     0.068169     0.000022     0.004643      0.717286  \n",
       "2        0.083227     0.072507     0.000004     0.002106      1.043919  \n",
       "3        0.080059     0.069942     0.000006     0.002414      0.242524  \n",
       "4        0.077461     0.070175     0.000002     0.001482      0.606258  \n",
       "...           ...          ...          ...          ...           ...  \n",
       "9115     0.653000    -0.879310     0.123917     0.352018      1.813520  \n",
       "9116     0.659650    -0.835960     0.167255     0.408968      1.483683  \n",
       "9117     0.632420    -0.837640     0.109532     0.330956      0.502392  \n",
       "9118     0.264780    -0.854420     0.059971     0.244890      1.467799  \n",
       "9119     0.267410    -0.849240     0.076105     0.275871      0.349721  \n",
       "\n",
       "[9120 rows x 55 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_LA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "bbcddf25",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\lee\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\ipykernel_launcher.py:7: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  import sys\n",
      "c:\\users\\lee\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\ipykernel_launcher.py:12: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  if sys.path[0] == \"\":\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# LabelEncoder 객체 생성\n",
    "label_encoder = LabelEncoder()\n",
    "\n",
    "# 'label' 컬럼을 숫자로 변환\n",
    "df_RA['activity'] = label_encoder.fit_transform(df_RA['activity'])\n",
    "\n",
    "# LabelEncoder 객체 생성\n",
    "label_encoder = LabelEncoder()\n",
    "# 'label' 컬럼을 숫자로 변환\n",
    "df_LA['activity'] = label_encoder.fit_transform(df_LA['activity'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2001b197",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "12    480\n",
       "18    480\n",
       "6     480\n",
       "10    480\n",
       "4     480\n",
       "3     480\n",
       "2     480\n",
       "15    480\n",
       "11    480\n",
       "17    480\n",
       "13    480\n",
       "16    480\n",
       "9     480\n",
       "14    480\n",
       "5     480\n",
       "0     480\n",
       "8     480\n",
       "7     480\n",
       "1     480\n",
       "Name: activity, dtype: int64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_LA['activity'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0cc7988e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "12    480\n",
       "18    480\n",
       "6     480\n",
       "10    480\n",
       "4     480\n",
       "3     480\n",
       "2     480\n",
       "15    480\n",
       "11    480\n",
       "17    480\n",
       "13    480\n",
       "16    480\n",
       "9     480\n",
       "14    480\n",
       "5     480\n",
       "0     480\n",
       "8     480\n",
       "7     480\n",
       "1     480\n",
       "Name: activity, dtype: int64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_RA['activity'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "28107640",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_RA_Y=df_RA['activity']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "343472b7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>RA_xacc_mean</th>\n",
       "      <th>RA_xacc_max</th>\n",
       "      <th>RA_xacc_min</th>\n",
       "      <th>RA_xacc_var</th>\n",
       "      <th>RA_xacc_std</th>\n",
       "      <th>RA_xacc_skew</th>\n",
       "      <th>RA_yacc_mean</th>\n",
       "      <th>RA_yacc_max</th>\n",
       "      <th>RA_yacc_min</th>\n",
       "      <th>RA_yacc_var</th>\n",
       "      <th>...</th>\n",
       "      <th>RA_ymag_min</th>\n",
       "      <th>RA_ymag_var</th>\n",
       "      <th>RA_ymag_std</th>\n",
       "      <th>RA_ymag_skew</th>\n",
       "      <th>RA_zmag_mean</th>\n",
       "      <th>RA_zmag_max</th>\n",
       "      <th>RA_zmag_min</th>\n",
       "      <th>RA_zmag_var</th>\n",
       "      <th>RA_zmag_std</th>\n",
       "      <th>RA_zmag_skew</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.679134</td>\n",
       "      <td>0.75930</td>\n",
       "      <td>0.58542</td>\n",
       "      <td>0.001546</td>\n",
       "      <td>0.039324</td>\n",
       "      <td>-0.415694</td>\n",
       "      <td>5.713088</td>\n",
       "      <td>5.8483</td>\n",
       "      <td>5.5956</td>\n",
       "      <td>0.003779</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.57428</td>\n",
       "      <td>0.000012</td>\n",
       "      <td>0.003401</td>\n",
       "      <td>-0.052190</td>\n",
       "      <td>-0.211136</td>\n",
       "      <td>-0.18401</td>\n",
       "      <td>-0.24523</td>\n",
       "      <td>0.000044</td>\n",
       "      <td>0.006638</td>\n",
       "      <td>-1.153902</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.644964</td>\n",
       "      <td>0.73158</td>\n",
       "      <td>0.53064</td>\n",
       "      <td>0.001333</td>\n",
       "      <td>0.036508</td>\n",
       "      <td>0.410625</td>\n",
       "      <td>5.795154</td>\n",
       "      <td>5.9546</td>\n",
       "      <td>5.6687</td>\n",
       "      <td>0.001132</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.57398</td>\n",
       "      <td>0.000005</td>\n",
       "      <td>0.002216</td>\n",
       "      <td>0.222740</td>\n",
       "      <td>-0.206431</td>\n",
       "      <td>-0.18054</td>\n",
       "      <td>-0.23624</td>\n",
       "      <td>0.000032</td>\n",
       "      <td>0.005660</td>\n",
       "      <td>0.458427</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.608212</td>\n",
       "      <td>0.67737</td>\n",
       "      <td>0.53546</td>\n",
       "      <td>0.000637</td>\n",
       "      <td>0.025244</td>\n",
       "      <td>0.153302</td>\n",
       "      <td>5.833086</td>\n",
       "      <td>5.8918</td>\n",
       "      <td>5.7656</td>\n",
       "      <td>0.000488</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.57563</td>\n",
       "      <td>0.000004</td>\n",
       "      <td>0.001954</td>\n",
       "      <td>-0.221765</td>\n",
       "      <td>-0.205648</td>\n",
       "      <td>-0.18342</td>\n",
       "      <td>-0.22933</td>\n",
       "      <td>0.000024</td>\n",
       "      <td>0.004868</td>\n",
       "      <td>-0.984915</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.591138</td>\n",
       "      <td>0.71177</td>\n",
       "      <td>0.51524</td>\n",
       "      <td>0.001349</td>\n",
       "      <td>0.036731</td>\n",
       "      <td>0.525019</td>\n",
       "      <td>5.863846</td>\n",
       "      <td>5.9645</td>\n",
       "      <td>5.7556</td>\n",
       "      <td>0.001423</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.57858</td>\n",
       "      <td>0.000007</td>\n",
       "      <td>0.002688</td>\n",
       "      <td>0.075011</td>\n",
       "      <td>-0.203739</td>\n",
       "      <td>-0.17999</td>\n",
       "      <td>-0.22958</td>\n",
       "      <td>0.000026</td>\n",
       "      <td>0.005099</td>\n",
       "      <td>0.185634</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.558168</td>\n",
       "      <td>0.67190</td>\n",
       "      <td>0.50535</td>\n",
       "      <td>0.000626</td>\n",
       "      <td>0.025020</td>\n",
       "      <td>1.076782</td>\n",
       "      <td>5.884745</td>\n",
       "      <td>5.9401</td>\n",
       "      <td>5.8384</td>\n",
       "      <td>0.000471</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.57996</td>\n",
       "      <td>0.000005</td>\n",
       "      <td>0.002278</td>\n",
       "      <td>-0.219440</td>\n",
       "      <td>-0.203684</td>\n",
       "      <td>-0.17904</td>\n",
       "      <td>-0.22924</td>\n",
       "      <td>0.000027</td>\n",
       "      <td>0.005175</td>\n",
       "      <td>-0.820907</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 54 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   RA_xacc_mean  RA_xacc_max  RA_xacc_min  RA_xacc_var  RA_xacc_std  \\\n",
       "0      0.679134      0.75930      0.58542     0.001546     0.039324   \n",
       "1      0.644964      0.73158      0.53064     0.001333     0.036508   \n",
       "2      0.608212      0.67737      0.53546     0.000637     0.025244   \n",
       "3      0.591138      0.71177      0.51524     0.001349     0.036731   \n",
       "4      0.558168      0.67190      0.50535     0.000626     0.025020   \n",
       "\n",
       "   RA_xacc_skew  RA_yacc_mean  RA_yacc_max  RA_yacc_min  RA_yacc_var  ...  \\\n",
       "0     -0.415694      5.713088       5.8483       5.5956     0.003779  ...   \n",
       "1      0.410625      5.795154       5.9546       5.6687     0.001132  ...   \n",
       "2      0.153302      5.833086       5.8918       5.7656     0.000488  ...   \n",
       "3      0.525019      5.863846       5.9645       5.7556     0.001423  ...   \n",
       "4      1.076782      5.884745       5.9401       5.8384     0.000471  ...   \n",
       "\n",
       "   RA_ymag_min  RA_ymag_var  RA_ymag_std  RA_ymag_skew  RA_zmag_mean  \\\n",
       "0     -0.57428     0.000012     0.003401     -0.052190     -0.211136   \n",
       "1     -0.57398     0.000005     0.002216      0.222740     -0.206431   \n",
       "2     -0.57563     0.000004     0.001954     -0.221765     -0.205648   \n",
       "3     -0.57858     0.000007     0.002688      0.075011     -0.203739   \n",
       "4     -0.57996     0.000005     0.002278     -0.219440     -0.203684   \n",
       "\n",
       "   RA_zmag_max  RA_zmag_min  RA_zmag_var  RA_zmag_std  RA_zmag_skew  \n",
       "0     -0.18401     -0.24523     0.000044     0.006638     -1.153902  \n",
       "1     -0.18054     -0.23624     0.000032     0.005660      0.458427  \n",
       "2     -0.18342     -0.22933     0.000024     0.004868     -0.984915  \n",
       "3     -0.17999     -0.22958     0.000026     0.005099      0.185634  \n",
       "4     -0.17904     -0.22924     0.000027     0.005175     -0.820907  \n",
       "\n",
       "[5 rows x 54 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_RA_X=df_RA.drop('activity',axis=1)\n",
    "df_RA_X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "cb09b8f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train_RA, X_test_RA, y_train_RA, y_test_RA = train_test_split(df_RA_X, \n",
    "                                                    df_RA_Y,\n",
    "                                                    test_size = 0.25, \n",
    "                                                    random_state = 21)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "1671afc5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    12\n",
       "1    12\n",
       "2    12\n",
       "3    12\n",
       "4    12\n",
       "Name: activity, dtype: int32"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_LA_Y = df_LA['activity']\n",
    "df_LA_Y.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "579f3464",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>LA_xacc_mean</th>\n",
       "      <th>LA_xacc_max</th>\n",
       "      <th>LA_xacc_min</th>\n",
       "      <th>LA_xacc_var</th>\n",
       "      <th>LA_xacc_std</th>\n",
       "      <th>LA_xacc_skew</th>\n",
       "      <th>LA_yacc_mean</th>\n",
       "      <th>LA_yacc_max</th>\n",
       "      <th>LA_yacc_min</th>\n",
       "      <th>LA_yacc_var</th>\n",
       "      <th>...</th>\n",
       "      <th>LA_ymag_min</th>\n",
       "      <th>LA_ymag_var</th>\n",
       "      <th>LA_ymag_std</th>\n",
       "      <th>LA_ymag_skew</th>\n",
       "      <th>LA_zmag_mean</th>\n",
       "      <th>LA_zmag_max</th>\n",
       "      <th>LA_zmag_min</th>\n",
       "      <th>LA_zmag_var</th>\n",
       "      <th>LA_zmag_std</th>\n",
       "      <th>LA_zmag_skew</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3.403317</td>\n",
       "      <td>3.4875</td>\n",
       "      <td>3.2682</td>\n",
       "      <td>0.001583</td>\n",
       "      <td>0.039790</td>\n",
       "      <td>-0.744647</td>\n",
       "      <td>-8.375713</td>\n",
       "      <td>-8.2927</td>\n",
       "      <td>-8.4821</td>\n",
       "      <td>0.001178</td>\n",
       "      <td>...</td>\n",
       "      <td>0.33748</td>\n",
       "      <td>0.000003</td>\n",
       "      <td>0.001810</td>\n",
       "      <td>-0.215069</td>\n",
       "      <td>0.072273</td>\n",
       "      <td>0.076374</td>\n",
       "      <td>0.067940</td>\n",
       "      <td>0.000004</td>\n",
       "      <td>0.001910</td>\n",
       "      <td>-0.166015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3.427302</td>\n",
       "      <td>3.6630</td>\n",
       "      <td>3.3168</td>\n",
       "      <td>0.004305</td>\n",
       "      <td>0.065614</td>\n",
       "      <td>1.000107</td>\n",
       "      <td>-8.397591</td>\n",
       "      <td>-8.3118</td>\n",
       "      <td>-8.5017</td>\n",
       "      <td>0.001098</td>\n",
       "      <td>...</td>\n",
       "      <td>0.33000</td>\n",
       "      <td>0.000017</td>\n",
       "      <td>0.004159</td>\n",
       "      <td>-0.611251</td>\n",
       "      <td>0.074557</td>\n",
       "      <td>0.085184</td>\n",
       "      <td>0.068169</td>\n",
       "      <td>0.000022</td>\n",
       "      <td>0.004643</td>\n",
       "      <td>0.717286</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3.400870</td>\n",
       "      <td>3.5168</td>\n",
       "      <td>3.3315</td>\n",
       "      <td>0.001007</td>\n",
       "      <td>0.031732</td>\n",
       "      <td>0.978319</td>\n",
       "      <td>-8.439138</td>\n",
       "      <td>-8.3599</td>\n",
       "      <td>-8.5204</td>\n",
       "      <td>0.000684</td>\n",
       "      <td>...</td>\n",
       "      <td>0.33307</td>\n",
       "      <td>0.000002</td>\n",
       "      <td>0.001316</td>\n",
       "      <td>-0.506255</td>\n",
       "      <td>0.075852</td>\n",
       "      <td>0.083227</td>\n",
       "      <td>0.072507</td>\n",
       "      <td>0.000004</td>\n",
       "      <td>0.002106</td>\n",
       "      <td>1.043919</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3.391002</td>\n",
       "      <td>3.5311</td>\n",
       "      <td>3.2608</td>\n",
       "      <td>0.001792</td>\n",
       "      <td>0.042328</td>\n",
       "      <td>0.117935</td>\n",
       "      <td>-8.441421</td>\n",
       "      <td>-8.3207</td>\n",
       "      <td>-8.5446</td>\n",
       "      <td>0.001862</td>\n",
       "      <td>...</td>\n",
       "      <td>0.33431</td>\n",
       "      <td>0.000002</td>\n",
       "      <td>0.001395</td>\n",
       "      <td>0.155251</td>\n",
       "      <td>0.074878</td>\n",
       "      <td>0.080059</td>\n",
       "      <td>0.069942</td>\n",
       "      <td>0.000006</td>\n",
       "      <td>0.002414</td>\n",
       "      <td>0.242524</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3.359974</td>\n",
       "      <td>3.4434</td>\n",
       "      <td>3.3069</td>\n",
       "      <td>0.000633</td>\n",
       "      <td>0.025160</td>\n",
       "      <td>1.051627</td>\n",
       "      <td>-8.454854</td>\n",
       "      <td>-8.3202</td>\n",
       "      <td>-8.5561</td>\n",
       "      <td>0.001061</td>\n",
       "      <td>...</td>\n",
       "      <td>0.33631</td>\n",
       "      <td>0.000001</td>\n",
       "      <td>0.001005</td>\n",
       "      <td>-0.299017</td>\n",
       "      <td>0.073398</td>\n",
       "      <td>0.077461</td>\n",
       "      <td>0.070175</td>\n",
       "      <td>0.000002</td>\n",
       "      <td>0.001482</td>\n",
       "      <td>0.606258</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 54 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   LA_xacc_mean  LA_xacc_max  LA_xacc_min  LA_xacc_var  LA_xacc_std  \\\n",
       "0      3.403317       3.4875       3.2682     0.001583     0.039790   \n",
       "1      3.427302       3.6630       3.3168     0.004305     0.065614   \n",
       "2      3.400870       3.5168       3.3315     0.001007     0.031732   \n",
       "3      3.391002       3.5311       3.2608     0.001792     0.042328   \n",
       "4      3.359974       3.4434       3.3069     0.000633     0.025160   \n",
       "\n",
       "   LA_xacc_skew  LA_yacc_mean  LA_yacc_max  LA_yacc_min  LA_yacc_var  ...  \\\n",
       "0     -0.744647     -8.375713      -8.2927      -8.4821     0.001178  ...   \n",
       "1      1.000107     -8.397591      -8.3118      -8.5017     0.001098  ...   \n",
       "2      0.978319     -8.439138      -8.3599      -8.5204     0.000684  ...   \n",
       "3      0.117935     -8.441421      -8.3207      -8.5446     0.001862  ...   \n",
       "4      1.051627     -8.454854      -8.3202      -8.5561     0.001061  ...   \n",
       "\n",
       "   LA_ymag_min  LA_ymag_var  LA_ymag_std  LA_ymag_skew  LA_zmag_mean  \\\n",
       "0      0.33748     0.000003     0.001810     -0.215069      0.072273   \n",
       "1      0.33000     0.000017     0.004159     -0.611251      0.074557   \n",
       "2      0.33307     0.000002     0.001316     -0.506255      0.075852   \n",
       "3      0.33431     0.000002     0.001395      0.155251      0.074878   \n",
       "4      0.33631     0.000001     0.001005     -0.299017      0.073398   \n",
       "\n",
       "   LA_zmag_max  LA_zmag_min  LA_zmag_var  LA_zmag_std  LA_zmag_skew  \n",
       "0     0.076374     0.067940     0.000004     0.001910     -0.166015  \n",
       "1     0.085184     0.068169     0.000022     0.004643      0.717286  \n",
       "2     0.083227     0.072507     0.000004     0.002106      1.043919  \n",
       "3     0.080059     0.069942     0.000006     0.002414      0.242524  \n",
       "4     0.077461     0.070175     0.000002     0.001482      0.606258  \n",
       "\n",
       "[5 rows x 54 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_LA_X=df_LA.drop('activity',axis=1)\n",
    "df_LA_X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "af5e2370",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train_LA, X_test_LA, y_train_LA, y_test_LA = train_test_split(df_LA_X, \n",
    "                                                    df_LA_Y,\n",
    "                                                    test_size = 0.25, \n",
    "                                                    random_state = 21)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "ef5f2cb0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((6840, 54), (2280, 54), (6840,), (2280,))"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_RA.shape, X_test_RA.shape, y_train_RA.shape, y_test_RA.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "d5a15460",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((6840, 54), (2280, 54), (6840,), (2280,))"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_LA.shape, X_test_LA.shape, y_train_LA.shape, y_test_LA.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "7e0d2eed",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "import numpy as np\n",
    "\n",
    "def split_sequences(sequences, n_steps):\n",
    "    X, y = list(), list()  # 빈 리스트를 생성하여 시퀀스 데이터와 레이블을 담을 공간을 만듦\n",
    "    for i in range(len(sequences)):  # 전체 시퀀스 데이터를 순회\n",
    "        # find the end of this pattern\n",
    "        end_ix = i + n_steps  # 현재 인덱스(i)에서 n_steps만큼 떨어진 시퀀스의 끝을 계산\n",
    "        # check if we are beyond the dataset\n",
    "        if end_ix > len(sequences):  # 시퀀스 끝이 데이터의 범위를 넘어서는지 확인\n",
    "            break  # 범위를 넘으면 루프 종료\n",
    "        # gather input (X) and output parts (y)\n",
    "        seq_x = sequences[i:end_ix, :-1]  # 입력 데이터 (특징 데이터)\n",
    "        seq_y_values = sequences[i:end_ix, -1]  # 시퀀스 동안의 출력 데이터 (레이블들)\n",
    "        \n",
    "        # 가장 빈번하게 나온 레이블 찾기\n",
    "        most_common_label = Counter(seq_y_values).most_common(1)[0][0]\n",
    "        \n",
    "        X.append(seq_x)  # 입력 데이터 추가\n",
    "        y.append(most_common_label)  # 가장 많이 나온 레이블 추가\n",
    "    \n",
    "    return np.array(X), np.array(y)  # 리스트를 numpy 배열로 변환하여 반환"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "d3266d9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge train and test X/y data to apply sequence transformation function\n",
    "y_train_array_RA = np.array(y_train_RA)\n",
    "train_set_RA = np.c_[X_train_RA, y_train_array_RA]\n",
    "\n",
    "y_test_array_RA = np.array(y_test_RA)\n",
    "test_set_RA = np.c_[X_test_RA, y_test_array_RA]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "78095b7c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(6838, 3, 54) (6838,)\n",
      "(2278, 3, 54) (2278,)\n"
     ]
    }
   ],
   "source": [
    "n_step = 3 \n",
    "\n",
    "X_train_seq_RA, y_train_seq_RA = split_sequences(train_set_RA, n_step)\n",
    "print(X_train_seq_RA.shape, y_train_seq_RA.shape)\n",
    "\n",
    "X_test_seq_RA, y_test_seq_RA = split_sequences(test_set_RA, n_step)\n",
    "print(X_test_seq_RA.shape, y_test_seq_RA.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "cd0fb401",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge train and test X/y data to apply sequence transformation function\n",
    "y_train_array_LA = np.array(y_train_LA)\n",
    "train_set_LA = np.c_[X_train_LA, y_train_array_LA]\n",
    "\n",
    "y_test_array_LA = np.array(y_test_LA)\n",
    "test_set_LA = np.c_[X_test_LA, y_test_array_LA]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "c021edf3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(6838, 3, 54) (6838,)\n",
      "(2278, 3, 54) (2278,)\n"
     ]
    }
   ],
   "source": [
    "n_step = 3 \n",
    "\n",
    "X_train_seq_LA, y_train_seq_LA = split_sequences(train_set_LA, n_step)\n",
    "print(X_train_seq_LA.shape, y_train_seq_LA.shape)\n",
    "\n",
    "X_test_seq_LA, y_test_seq_LA = split_sequences(test_set_LA, n_step)\n",
    "print(X_test_seq_LA.shape, y_test_seq_LA.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "05ca26ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(6838, 19)\n",
      "(2278, 19)\n"
     ]
    }
   ],
   "source": [
    "from keras.utils import to_categorical\n",
    "\n",
    "# Convert output variables to categorical for CNN\n",
    "y_train_seq_RA = to_categorical(y_train_seq_RA)\n",
    "print(y_train_seq_RA.shape)\n",
    "\n",
    "y_test_seq_RA = to_categorical(y_test_seq_RA)\n",
    "print(y_test_seq_RA.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "c37ee4b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(6838, 19)\n",
      "(2278, 19)\n"
     ]
    }
   ],
   "source": [
    "# Convert output variables to categorical for CNN\n",
    "y_train_seq_LA = to_categorical(y_train_seq_LA)\n",
    "print(y_train_seq_LA.shape)\n",
    "\n",
    "y_test_seq_LA = to_categorical(y_test_seq_LA)\n",
    "print(y_test_seq_LA.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "74e7e78d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3 54 19\n"
     ]
    }
   ],
   "source": [
    "# Produce variables for CNN input/output shape\n",
    "n_timesteps, n_features, n_outputs = X_train_seq_RA.shape[1], X_train_seq_RA.shape[2], y_train_seq_RA.shape[1]\n",
    "print(n_timesteps, n_features, n_outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "caf616dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "\n",
    "# cnn model vary kernel size\n",
    "from numpy import mean\n",
    "from numpy import std\n",
    "from numpy import dstack\n",
    "from pandas import read_csv\n",
    "from matplotlib import pyplot\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.layers import Flatten\n",
    "from tensorflow.keras.layers import Dropout\n",
    "from tensorflow.keras import layers, models\n",
    "from keras.utils import to_categorical\n",
    "\n",
    "import tensorflow.keras\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout, Flatten, Reshape, LSTM, Conv1D, MaxPooling1D\n",
    "from tensorflow.keras.layers import TimeDistributed, Conv1D, MaxPooling1D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "f2f35db1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build CNN model using keras. For model building suggestions, referenced:\n",
    "# https://machinelearningmastery.com/deep-learning-models-for-human-activity-recognition/\n",
    "# https://machinelearningmastery.com/how-to-choose-loss-functions-when-training-deep-learning-neural-networks/\n",
    "# https://machinelearningmastery.com/how-to-develop-convolutional-neural-network-models-for-time-series-forecasting/\n",
    "\n",
    "# Sequential model type\n",
    "model = Sequential()\n",
    "model.add(LSTM(units=128, input_shape = (n_timesteps,n_features)))\n",
    "model.add(Dense(128, activation='relu'))\n",
    "model.add(Dense(n_outputs, activation='softmax'))\n",
    "model.compile(optimizer='adam', metrics=['accuracy'], loss='categorical_crossentropy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "1b22db37",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " lstm (LSTM)                 (None, 128)               93696     \n",
      "                                                                 \n",
      " dense (Dense)               (None, 128)               16512     \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 19)                2451      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 112,659\n",
      "Trainable params: 112,659\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "0e5186b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "193/193 [==============================] - 7s 13ms/step - loss: 2.0922 - accuracy: 0.3356 - val_loss: 1.3883 - val_accuracy: 0.5556\n",
      "Epoch 2/20\n",
      "193/193 [==============================] - 2s 11ms/step - loss: 1.0978 - accuracy: 0.6469 - val_loss: 0.9932 - val_accuracy: 0.7120\n",
      "Epoch 3/20\n",
      "193/193 [==============================] - 2s 10ms/step - loss: 0.7588 - accuracy: 0.7785 - val_loss: 0.8099 - val_accuracy: 0.7836\n",
      "Epoch 4/20\n",
      "193/193 [==============================] - 2s 8ms/step - loss: 0.5880 - accuracy: 0.8260 - val_loss: 0.7431 - val_accuracy: 0.7924\n",
      "Epoch 5/20\n",
      "193/193 [==============================] - 2s 12ms/step - loss: 0.4794 - accuracy: 0.8624 - val_loss: 0.6709 - val_accuracy: 0.8260\n",
      "Epoch 6/20\n",
      "193/193 [==============================] - 1s 7ms/step - loss: 0.4036 - accuracy: 0.8780 - val_loss: 0.6151 - val_accuracy: 0.8392\n",
      "Epoch 7/20\n",
      "193/193 [==============================] - 3s 14ms/step - loss: 0.3294 - accuracy: 0.9020 - val_loss: 0.6252 - val_accuracy: 0.8275\n",
      "Epoch 8/20\n",
      "193/193 [==============================] - 1s 6ms/step - loss: 0.2726 - accuracy: 0.9201 - val_loss: 0.5972 - val_accuracy: 0.8553\n",
      "Epoch 9/20\n",
      "193/193 [==============================] - 2s 8ms/step - loss: 0.2282 - accuracy: 0.9321 - val_loss: 0.6208 - val_accuracy: 0.8319\n",
      "Epoch 10/20\n",
      "193/193 [==============================] - 2s 9ms/step - loss: 0.1876 - accuracy: 0.9483 - val_loss: 0.5694 - val_accuracy: 0.8567\n",
      "Epoch 11/20\n",
      "193/193 [==============================] - 2s 8ms/step - loss: 0.1498 - accuracy: 0.9556 - val_loss: 0.6356 - val_accuracy: 0.8450\n",
      "Epoch 12/20\n",
      "193/193 [==============================] - 1s 8ms/step - loss: 0.1160 - accuracy: 0.9686 - val_loss: 0.6160 - val_accuracy: 0.8670\n",
      "Epoch 13/20\n",
      "193/193 [==============================] - 1s 5ms/step - loss: 0.1043 - accuracy: 0.9706 - val_loss: 0.6222 - val_accuracy: 0.8596\n",
      "Epoch 14/20\n",
      "193/193 [==============================] - 1s 8ms/step - loss: 0.0714 - accuracy: 0.9825 - val_loss: 0.6572 - val_accuracy: 0.8582\n",
      "Epoch 15/20\n",
      "193/193 [==============================] - 2s 11ms/step - loss: 0.0603 - accuracy: 0.9865 - val_loss: 0.6231 - val_accuracy: 0.8713\n",
      "Epoch 16/20\n",
      "193/193 [==============================] - 1s 6ms/step - loss: 0.0428 - accuracy: 0.9922 - val_loss: 0.6966 - val_accuracy: 0.8523\n",
      "Epoch 17/20\n",
      "193/193 [==============================] - 2s 8ms/step - loss: 0.0505 - accuracy: 0.9883 - val_loss: 0.7503 - val_accuracy: 0.8450\n",
      "Epoch 18/20\n",
      "193/193 [==============================] - 2s 11ms/step - loss: 0.0368 - accuracy: 0.9922 - val_loss: 0.6775 - val_accuracy: 0.8596\n",
      "Epoch 19/20\n",
      "193/193 [==============================] - 1s 8ms/step - loss: 0.0213 - accuracy: 0.9972 - val_loss: 0.6920 - val_accuracy: 0.8684\n",
      "Epoch 20/20\n",
      "193/193 [==============================] - 3s 14ms/step - loss: 0.0157 - accuracy: 0.9982 - val_loss: 0.7297 - val_accuracy: 0.8728\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(X_train_seq_RA, y_train_seq_RA, epochs = 20, batch_size = 32, validation_split = 0.1, shuffle = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "151c5d3b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x1ea0db06dc8>"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAiMAAAGdCAYAAADAAnMpAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjUuMywgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/NK7nSAAAACXBIWXMAAA9hAAAPYQGoP6dpAABNyElEQVR4nO3dd3zTdeI/8FeSJmnTke4FXUDZpWxscYMgehzoqYgD8dTzFE859HseN9Tzvl859+RETxGVU3Eg3k89FJChtCCrbMrqArpH0pXR5PP745OkDV1Jm/STtK/n45FH0s/K+9MPIa++P+8hEwRBABEREZFE5FIXgIiIiAY2hhEiIiKSFMMIERERSYphhIiIiCTFMEJERESSYhghIiIiSTGMEBERkaQYRoiIiEhSAVIXwBVWqxUXLlxAaGgoZDKZ1MUhIiIiFwiCgPr6eiQmJkIu77z+wy/CyIULF5CUlCR1MYiIiKgHSkpKMHjw4E7X+0UYCQ0NBSCeTFhYmMSlISIiIlfo9XokJSU5vsc74xdhxH5rJiwsjGGEiIjIz3TXxIINWImIiEhSDCNEREQkKYYRIiIikpRftBkhIiLyBkEQ0NLSAovFInVR/JJCoUBAQECvh91gGCEiogHJZDKhtLQUTU1NUhfFr2k0GiQkJEClUvX4GAwjREQ04FitVhQUFEChUCAxMREqlYqDarpJEASYTCZUVlaioKAA6enpXQ5s1hWGESIiGnBMJhOsViuSkpKg0WikLo7fCgoKglKpRFFREUwmEwIDA3t0HDZgJSKiAaunf8lTK0/8DnkViIiISFIMI0RERCQphhEiIqIBKjU1Fa+88orUxWADViIiIn9y5ZVXYvz48R4JEXv27EFwcHDvC9VLA7pm5P2cQvzh84Moqm6UuihEREQeYR/IzRUxMTE+0ZtoQIeR9QfO49O953C8VC91UYiISGKCIKDJ1CLJQxAEl8q4ePFibN++Ha+++ipkMhlkMhnWrFkDmUyG//73v5g0aRLUajV++uknnDlzBvPmzUNcXBxCQkIwZcoUbN682el4F9+mkclkeOedd3DDDTdAo9EgPT0d//nPfzz5a+7QgL5NMyQ6GAdL6nC2ijUjREQDXbPZgtFPfCfJex97ejY0qu6/kl999VWcPHkSY8eOxdNPPw0AOHr0KADgj3/8I1544QUMGTIEERERKCkpwXXXXYf/+7//g1qtxgcffIC5c+ciPz8fycnJnb7H3/72Nzz33HN4/vnn8frrr+P2229HUVERIiMjPXOyHRjQNSNp0eJ9soJKhhEiIvJ9Wq0WKpUKGo0G8fHxiI+Ph0KhAAA8/fTTuOaaazB06FBERkYiMzMT999/P8aOHYv09HT8/e9/x9ChQ7ut6Vi8eDEWLlyIYcOG4ZlnnkFDQwN+/vlnr57XgK4ZsYeRQrYZISIa8IKUChx7erZk791bkydPdvq5oaEBTz31FL755huUlpaipaUFzc3NKC4u7vI448aNc7wODg5GWFgYKioqel2+rjCMACjgbRoiogFPJpO5dKvEV13cK+axxx7Dpk2b8MILL2DYsGEICgrCTTfdBJPJ1OVxlEql088ymQxWq9Xj5W3Lf3/rHpBqCyNVDSboms3QBim72YOIiEhaKpUKFoul2+127tyJxYsX44YbbgAg1pQUFhZ6uXQ9M6DbjISoAxAbqgYAFLJ2hIiI/EBqaip2796NwsJCVFVVdVprkZ6ejvXr1yMvLw8HDx7Ebbfd5vUajp4a0GEEYLsRIiLyL4899hgUCgVGjx6NmJiYTtuAvPTSS4iIiEB2djbmzp2L2bNnY+LEiX1cWtcM6Ns0gBhGdhfU4Cx71BARkR8YPnw4cnNznZYtXry43Xapqan44YcfnJYtWbLE6eeLb9t0NN5JXV1dj8rpDtaMsBErERGRpBhGGEaIiIgk5VYYWbFiBaZMmYLQ0FDExsZi/vz5yM/P73a/zz77DCNHjkRgYCAyMjLw7bff9rjAnjYkxtZmpKrR5eF4iYiIyHPcCiPbt2/HkiVLsGvXLmzatAlmsxmzZs1CY2PntQo5OTlYuHAh7rnnHhw4cADz58/H/PnzceTIkV4X3hOSIjWQy4B6YwuqGrrue01ERESeJxN6UR1QWVmJ2NhYbN++HZdffnmH2yxYsACNjY34+uuvHcsuueQSjB8/HqtWrXLpffR6PbRaLXQ6HcLCwnpa3E5d9twPKKlpxqf3Z2FqmvfG3iciIt9gMBhQUFCAtLQ0BAYGSl0cv9bV79LV7+9etRnR6XQA0OXkObm5uZg5c6bTstmzZ7drCdyW0WiEXq93enhTWnQIAKCgqsGr70NERETt9TiMWK1WLF26FNOnT8fYsWM73a6srAxxcXFOy+Li4lBWVtbpPitWrIBWq3U8kpKSelpMlwxxNGJt8ur7EBERUXs9DiNLlizBkSNH8Mknn3iyPACA5cuXQ6fTOR4lJSUef4+2WnvUsGaEiIior/Vo0LOHHnoIX3/9NXbs2IHBgwd3uW18fDzKy8udlpWXlyM+Pr7TfdRqNdRqdU+K1iOp7N5LREQkGbdqRgRBwEMPPYQvv/wSP/zwA9LS0rrdJysrC1u2bHFatmnTJmRlZblXUi8a4hgSvgkWK7v3EhGR77ryyiuxdOlSjx1v8eLFmD9/vseO1xNuhZElS5Zg7dq1+OijjxAaGoqysjKUlZWhubnZsc2iRYuwfPlyx8+PPPIINm7ciBdffBEnTpzAU089hb179+Khhx7y3Fn0UmJ4EFQKOUwtVlyoa+5+ByIiIvIYt8LIm2++CZ1OhyuvvBIJCQmOx7p16xzbFBcXo7S01PFzdnY2PvroI7z99tvIzMzE559/jg0bNnTZ6LWvKeQypERpAHDCPCIi8l2LFy/G9u3b8eqrr0Imk0Emk6GwsBBHjhzBnDlzEBISgri4ONx5552oqqpy7Pf5558jIyMDQUFBiIqKwsyZM9HY2IinnnoK77//Pr766ivH8bZt29bn5+VWmxFXhiTp6CRuvvlm3Hzzze68VZ9LjQ7GqYoGFFQ14rL0GKmLQ0REfU0QALNEvSqVGkAm63azV199FSdPnsTYsWPx9NNPi7sqlZg6dSruvfdevPzyy2hubsbjjz+OW265BT/88ANKS0uxcOFCPPfcc7jhhhtQX1+PH3/8EYIg4LHHHsPx48eh1+vx3nvvAeh6uA5vGfCz9trZ241w9l4iogHK3AQ8kyjNe//pAqAK7nYzrVYLlUoFjUbj6Ajyv//7v5gwYQKeeeYZx3arV69GUlISTp48iYaGBrS0tODGG29ESkoKACAjI8OxbVBQEIxGY5cdS7yNYcSGE+YREZE/OnjwILZu3YqQkJB2686cOYNZs2ZhxowZyMjIwOzZszFr1izcdNNNiIiIkKC0HWMYsUlz9KhhGCEiGpCUGrGGQqr37qGGhgbMnTsXzz77bLt1CQkJUCgU2LRpE3JycvD999/j9ddfx5///Gfs3r3bpV6xfYFhxMYeRkpqmmBqsUIV0KuR8omIyN/IZC7dKpGaSqWCxWJx/Dxx4kR88cUXSE1NRUBAx1/rMpkM06dPx/Tp0/HEE08gJSUFX375JZYtW9bueFLgN65NTKgawSoFrAJQXMNh4YmIyDelpqZi9+7dKCwsRFVVFZYsWYKamhosXLgQe/bswZkzZ/Ddd9/h7rvvhsViwe7du/HMM89g7969KC4uxvr161FZWYlRo0Y5jnfo0CHk5+ejqqoKZrO5z8+JYcRGJpMhLYbtRoiIyLc99thjUCgUGD16NGJiYmAymbBz505YLBbMmjULGRkZWLp0KcLDwyGXyxEWFoYdO3bguuuuw/Dhw/GXv/wFL774IubMmQMAuO+++zBixAhMnjwZMTEx2LlzZ5+fE2/TtJEWHYIj5/UoZBghIiIfNXz48A5nvl+/fn2H248aNQobN27s9HgxMTH4/vvvPVa+nmDNSBtptoHPzjKMEBER9RmGkTZab9Nw9l4iIqK+wjDSRlq02EebbUaIiIj6DsNIG2lRYs1Iud6IRmOLxKUhIiIaGBhG2tBqlIgMVgHg4GdERER9hWHkIhwWnoho4HBlAljqmid+hwwjF3GEEU6YR0TUbymVSgBAUxMHuewt++/Q/jvtCY4zchHWjBAR9X8KhQLh4eGoqKgAAGg0GshkMolL5V8EQUBTUxMqKioQHh4OhULR42MxjFzEEUbYZoSIqF+Lj48HAEcgoZ4JDw93/C57imHkIqwZISIaGGQyGRISEhAbGyvJfCz9gVKp7FWNiB3DyEVSbd1765rMqG00IcLWu4aIiPonhULhkS9U6jk2YL1IkEqBRG0gAA4LT0RE1BcYRjqQartVwwnziIiIvI9hpANsN0JERNR3GEY6wDBCRETUdxhGOjDENnsv24wQERF5H8NIB+w9agqrGjlUMBERkZcxjHQgKVIDhVyGZrMF5Xqj1MUhIiLq1xhGOqBUyJEcqQEAnK1qkLg0RERE/RvDSCfYiJWIiKhvMIx0om27ESIiIvIehpFOpMWwZoSIiKgvMIx0Ykg0u/cSERH1BYaRTtjbjBRXN6HFYpW4NERERP0Xw0gn4sMCoQ6Qo8Uq4Hxds9TFISIi6rcYRjohl8sctSO8VUNEROQ9DCNdcHTvrWQYISIi8haGkS5wrBEiIiLvYxjpQirDCBERkdcxjHRhCMMIERGR1zGMdMF+m+aCrhkGs0Xi0hAREfVPDCNdiAxWISwwAIIAFFU3SV0cIiKifolhpAsymQxpMSEAgALO3ktEROQVDCPdSIvSAAAKqlgzQkRE5A0MI91Ii2bNCBERkTcxjHSDs/cSERF5F8NIN9i9l4iIyLsYRrphH/isqsEEvcEscWmIiIj6H4aRboSoAxATqgYAFLJ2hIiIyOMYRlzAOWqIiIi8h2HEBfZ2I2c5ey8REZHHMYy4wN5upLCaYYSIiMjTGEZcwNs0RERE3sMw4gJH997KRgiCIHFpiIiI+heGERckR2kgkwH1xhZUNZikLg4REVG/wjDiAnWAAoPCgwCw3QgREZGnMYy4KK3NrRoiIiLyHIYRFzm697IRKxERkUcxjLiotUcNZ+8lIiLyJIYRF6Wyey8REZFXMIy4aEh0CACgsLoJViu79xIREXkKw4iLBkUEQamQwdRixQVds9TFISIi6jcYRlykkMuQEsVbNURERJ7GMOKGVIYRIiIij2MYccOQGIYRIiIiT2MYcQMnzCMiIvI8hhE3MIwQERF5HsOIG+xhpKSmCaYWq8SlISIi6h8YRtwQG6qGRqWAVQBKapukLg4REVG/wDDiBplMxgnziIiIPIxhxE1sN0JERORZDCNuSuPsvURERB7FMOImexgpZBghIiLyCLfDyI4dOzB37lwkJiZCJpNhw4YNXW6/bds2yGSydo+ysrKelllSvE1DRETkWW6HkcbGRmRmZmLlypVu7Zefn4/S0lLHIzY21t239gn2MFKmN6DR2CJxaYiIiPxfgLs7zJkzB3PmzHH7jWJjYxEeHu72fr4mXKNChEaJ2iYzCqsbMSZRK3WRiIiI/FqftRkZP348EhIScM0112Dnzp1dbms0GqHX650evqS13QjHGiEiIuotr4eRhIQErFq1Cl988QW++OILJCUl4corr8T+/fs73WfFihXQarWOR1JSkreL6Za06BAAQEFVg8QlISIi8n9u36Zx14gRIzBixAjHz9nZ2Thz5gxefvllfPjhhx3us3z5cixbtszxs16v96lAYp+9l917iYiIes/rYaQjU6dOxU8//dTperVaDbVa3Yclck9qFHvUEBEReYok44zk5eUhISFBirf2CHbvJSIi8hy3a0YaGhpw+vRpx88FBQXIy8tDZGQkkpOTsXz5cpw/fx4ffPABAOCVV15BWloaxowZA4PBgHfeeQc//PADvv/+e8+dRR9LjdYAAOqazKhtNCEiWCVxiYiIiPyX22Fk7969uOqqqxw/29t23HXXXVizZg1KS0tRXFzsWG8ymfDoo4/i/Pnz0Gg0GDduHDZv3ux0DH+jUQUgQRuIUp0BBdWNDCNERES9IBMEQZC6EN3R6/XQarXQ6XQICwuTujgAgIVv70Lu2Wq8eHMmfjVpsNTFISIi8jmufn9zbpoeSothuxEiIiJPYBjpoSH2RqzVDCNERES9wTDSQ44eNZUMI0RERL3BMNJDbbv3+kGzGyIiIp/FMNJDSZEaKOQyNJstKNcbpS4OERGR32IY6SGlQo6kiCAAbMRKRETUGwwjvcCRWImIiHqPYaQXOHsvERFR7zGM9EKabVh41owQERH1HMNIL7TWjDCMEBER9dTADSNWC5DzBvDWFUBjdY8OYR+FtbimCS0WqydLR0RENGAM3DAiVwCH1gGlecCRL3p0iISwQKgD5DBbBJyva/Zs+YiIiAaIgRtGAGD8beJz3r97tLtcLkNqlFg7cpa3aoiIiHpkYIeRjJsBeYBYO1JxvEeH4LDwREREvTOww0hwNJA+W3yd91GPDmFvN1LICfOIiIh6ZGCHEQAYv1B8PvQpYGlxe3cOfEZERNQ7DCPps4GgSKChDDi7ze3d7WHkLG/TEBER9QjDSIAKyLhJfH3Q/Vs19jByQdcMg9niyZIRERENCAwjAJBpu1Vz4hvAoHNr16hgFUIDAyAI4ngjRERE5B6GEQBInADEjARaDMDRL93aVSaTYQhv1RAREfUYwwgAyGSttSN5H7u9eyobsRIREfUYw4jduAWATA6U7AKqz7i1a2uPGs7eS0RE5C6GEbuwBGDIVeLrg5+4tas9jBRWsc0IERGRuxhG2rIPD3/wE8Dq+sR3Q2yz93JIeCIiIvcxjLQ18npAHQboioGinS7vlhqtAQBUNRihN5i9VToiIqJ+iWGkLWUQMGa++Pqg6w1ZQwOViA5RAwAKWTtCRETkFoaRi2XabtUc+wowuR4shrBHDRERUY8wjFws+RIgIg0wNQDH/5/Lu3GOGiIiop5hGLmY05gjrg8Pz7FGiIiIeoZhpCOZt4rPBTsA3TmXdmHNCBERUc8wjHQkIgVIuRSA4PKYI0NiWsOIIAheLBwREVH/wjDSmfG2WzUHPwZcCBfJkRrIZEC9oQXVjSYvF46IiKj/YBjpzOh5gFIDVJ8Gzu3tdvNApQKJ2iAAvFVDRETkDoaRzqhDgVFzxdcHXWvI6rhVw9l7iYiIXMYw0hX78PBHvgDMhm43tzdi5bDwRERErmMY6Urq5UDYYMCgA/K/7Xbz1gnzGEaIiIhcxTDSFbkcyFwgvnZheHiONUJEROQ+hpHu2AdAO70FqC/vclPHkPDVjbBa2b2XiIjIFQwj3YlOBwZPAQQLcPjTLjcdFB4EpUIGU4sVF3TNfVRAIiIi/8Yw4grH8PBdjzkSoJAjOVIDACisauqLkhEREfk9hhFXjL0RUKiBiqNA2aEuN20dFr6hL0pGRETk9xhGXBEUAYyYI77O67ohK7v3EhERuYdhxFX2MUcOfwZYzJ1ulhYdAoA9aoiIiFzFMOKqoTOA4FigqQo4tanTzTjWCBERkXsYRlylCADG3SK+7mJ4eHsYKalthqnF2hclIyIi8msMI+6w96rJ3wg01XS4SVyYGkFKBSxWASW17FFDRETUHYYRd8SPBeIzAKtZnK+mAzKZrLVHDSfMIyIi6hbDiLsybQ1Z87q4VWObvbewmmGEiIioOwwj7sq4GZAHABf2A5X5HW6SFsXuvURERK5iGHFXSAww7BrxdSe1I7xNQ0RE5DqGkZ4Yb2vIemgdYLW0W22/TcOxRoiIiLrHMNITw68FAsOB+lLg7LZ2q+2z95bpDWgytfRt2YiIiPwMw0hPBKiBjJvE1wfbDw8frlEhQqMEwAnziIiIusMw0lP2XjXHvwYM+narU6N5q4aIiMgVDCM9NWgiED0caGkGjm1ot5qz9xIREbmGYaSnZLLWEVk7mMl3CGfvJSIicgnDSG9k3grI5EBxDlBT4LTKPnsvJ8wjIiLqGsNIb4QlAkOuFF8f/MRpVWq0BgDbjBAREXWHYaS37A1ZD34EWFtn6U2LDkaAXIbaJjOOXtBJVDgiIiLfxzDSWyOvB1ShQF2xeLvGRqMKwLVj4wEAa3YWSlQ4IiIi38cw0lsqDTBmvvj6ooasd09PAwB8dfACqhuMfVwwIiIi/8Aw4gnjbbdqjm0ATK1tRCYmhyNzsBamFis+2l0sTdmIiIh8HMOIJyRnARGpgKlBHATNRiaTYfH0VADAh7uKYLZYO96fiIhoAGMY8YS2Y44cdJ7J9/qMRMSEqlFRb8S3h0slKBwREZFvYxjxlMxbxeez2wHdOcdiVYAcd0xLAQC8x4asRERE7TCMeEpEKpAyHYAAHFrntOq2aclQKeTIK6nDgeJaSYpHRETkqxhGPKnt8PCC4FgcE6rGLzITAABrcgolKBgREZHvYhjxpNHzgIAgoPoUcH6f06pf27r5fnOoFOV6gxSlIyIi8kkMI54UGAaMmiu+znNuyDp2kBZTUiPQYhWwdleRBIUjIiLyTQwjnjbedqvmyBdAi/NAZ/ZB0D7aXQyD2dLXJSMiIvJJboeRHTt2YO7cuUhMTIRMJsOGDRu63Wfbtm2YOHEi1Go1hg0bhjVr1vSgqH4i7QogNBEw1AH5/3VaNWt0HBK1gahuNOH/HbwgTfmIiIh8jNthpLGxEZmZmVi5cqVL2xcUFOD666/HVVddhby8PCxduhT33nsvvvvuO7cL6xfkCiBzgfj6oPPw8AEKOe7MSgUgdvMV2jRyJSIiGqhkQi++EWUyGb788kvMnz+/020ef/xxfPPNNzhy5Ihj2a233oq6ujps3LjRpffR6/XQarXQ6XQICwvraXH7TuVJYOUUQKYAHj0BhMQ6VtU1mXDJii0wmK1Y95tLMG1IlIQFJSIi8h5Xv7+93mYkNzcXM2fOdFo2e/Zs5ObmdrqP0WiEXq93eviVmOHAoEmAYAEOf+a0Klyjwg0TBgPgIGhERERAH4SRsrIyxMXFOS2Li4uDXq9Hc3Nzh/usWLECWq3W8UhKSvJ2MT3PPubIgX8DVuc5aRZnpwIAvj9WhnO1TX1cMCIiIt/ik71pli9fDp1O53iUlJRIXST3jf2VOOZIxVFgx/NOq0bEh2L6sChYBeDDXHbzJSKigc3rYSQ+Ph7l5eVOy8rLyxEWFoagoKAO91Gr1QgLC3N6+B1NJHD9C+Lrbc+061lzd7bYzffjn4vRZGrp69IRERH5DK+HkaysLGzZssVp2aZNm5CVleXtt5behDuAKfeJr9f/Bqg65Vh19chYpERpoDe0YP3+8xIVkIiISHpuh5GGhgbk5eUhLy8PgNh1Ny8vD8XFxQDEWyyLFi1ybP/b3/4WZ8+exR/+8AecOHEC//znP/Hpp5/i97//vWfOwNdduwJIzgaMeuCT2wCD2BhXLpdhka2b75ocdvMlIqKBy+0wsnfvXkyYMAETJkwAACxbtgwTJkzAE088AQAoLS11BBMASEtLwzfffINNmzYhMzMTL774It555x3Mnj3bQ6fg4xRK4Jb3xYHQqk4CX/7W0aD15smDEaxS4HRFA346XSVxQYmIiKTRq3FG+orfjTPSkXP7gPfmABYjcOWfgCsfBwA89Z+jWJNTiKtHxmL14ikSF5KIiMhzfGacEbIZPAn4xUvi6zYNWu+ydfP94UQFCqoaJSocERGRdBhG+lIHDVrTooNx1YgYAMD7OYXSlY2IiEgiDCN9bfYzQHKWU4NW+2y+n+87h3qDWeICEhER9S2Gkb4WoAJu+cCpQetlwyIxLDYEDcYWfLb3nNQlJCIi6lMMI1IIiQUWrAUUKiD/G8h2vOAYIv793EJYrT7fppiIiMhjGEakMngScH1rg9abQo8gLDAARdVN2JpfIW3ZiIiI+hDDiJQm3glMuRcAEPif3+LBDLFGhLP5EhHRQMIwIrXZKxwNWu8592eEyZrw0+kqnCyvl7pkREREfYJhRGptGrQqa0/jg4j3IIMVa9jNl4iIBgiGEV8QEgss+BBQqDC+aSceUmzA+v3nUNdkkrpkREREXscw4isGT3Y0aP298gtkW/bikz0lEheKiIjI+xhGfImtQascAl5RrsS2n3aixWKVulRERERexTDia2avgDXpEoTJmvG/xhXYevCM1CUiIiLyKoYRXxOggvyWD1CvisUw+QVov3sYsLJ2hIiI+i+GEV8UGgfTr9bAJARgqjEH5d/8r9QlIiIi8hqGER8VNWI6Pk9YBgCI2fcSkL9R4hIRERF5B8OIDxt13YP4oOUayCHA+sW9QNUpqYtERETkcQwjPmxCcgS+in8IP1tHQG6qBz65DTDopS4WERGRRzGM+LhFl6ZjiekRlCMSqDoJbHiADVqJiKhfYRjxcXPGJkAWGof7jUthkSuBE18DP74gdbGIiIg8hmHEx6kC5LjzkhTkCcOwUrNEXLj1GTZoJSKifoNhxA/cNi0ZqgA5XqqaisqRdwAQgPX3AVWnpS4aERFRrzGM+IGoEDV+mZkIAPg/611AchZg1LNBKxER9QsMI37i7umpAICvj1Sh4tq3gdBEoCofePcaIO8joIUz/BIRkX9iGPETYxK1mJoWiRargA8ONwML1gJqLVB5Quxh82omsPNVwKCTuqhERERuYRjxI7+21Y589HMxDHHjgaUHgRlPAiHxQP0FYNMTwEtjgO/+DOjOSVpWIiIiVzGM+JGZo+IwKDwINY0m/CfvAhAUAVy2DFh6CJi3EogZCZjqgdw3xJqS9b8Byg5LXWwiIqIuMYz4kQCFHIuyUgAAq3cWQBAE2wo1MOEO4MFdwG2fAamXAdYW4NA6YNWlwAfzgdNbAPv2REREPoRhxM/cOiUZQUoFTpTVY3dBjfNKmQwYPgtY/DVw31Zg7K8AmQI4uxVYe6MYTA5+AljM0hSeiIioAwwjfkarUeLGiYMAAO/tLOh8w0ETgZtWAw8fAKY9ACiDgfIjwJf32xq7vsZuwURE5BMYRvzQ4uxUAMCmY+UoqWnqeuOIFGDOP4DfHwFmPAGExAH688CmvwIvjwG+/wugO+/9QhMREXWCYcQPpceF4rL0aFgF4N2fuqgdaUsTCVz2KLD0MPDLN4DoEeLAaTmvA6+OA9bfD5Qd8W7BiYiIOsAw4qfuuTQNALAmpxDfHCp1fccANTDxTltj10+BlEttjV0/AVZNBz68ATizlY1diaj/aDEBpzYBhTv5f5uPkgmC718ZvV4PrVYLnU6HsLAwqYvjM576z1GsySmEKkCOj++7BJNSInp2oPP7gJw3gGMbAMEqLovPALIfBsbcCCgCPFZmIqI+IQjAub3iH1pHvgCaa8XlgyYBVzwOpM8SG/2TV7n6/c0w4scsVgH3f7gXm49XICpYhS8fnI7kKE3PD1hbCOT+EzjwIWC2tUWJSBVv74y7FQhQeaLYRETeU1sIHPpU7DlYc6Z1eUi8OEJ1S7P4c+IEMZQMv5ahxIsYRgaIRmMLbnkrF0cv6DE0JhjrH5gOrUbZu4M21QB7VwO73gSaqsRl2mTgst8D428Xb/UQEfkKgw44ukEcW6loZ+typQYYNRfIvBVIu0L8vy3nNWDPO61/cCVkiqFkxHUDN5RYLeIAmQmZHv8dMIwMIOV6A+av3IlSnQHZQ6Ow5u6pUAV4oDmQqRHYt0ac86ahXFwWNgi49PfAhDsBZWDv34OIqCcsZuDMD8DBj4H8/wItBtsKGZB2OZC5UAwi6pD2+zZWiY33f/4XYG4Ul8Vn2ELJ9YC8nzentFqBimNA4Y9AwQ6xLY1RBzycB0SmefStGEYGmGMX9Lh5VQ4aTRbcPGkwnrtpHGSeSrjmZmD/B8BPLwP1tsayIfHApUuBSYsBZZBn3oeIqCuCAJQeFG/BHPkcaKxsXRczUqwBybgF0A5y7XiN1eL0GT+/DZgaxGVxY4Er/gCMnNt/QokgANWnxeBRsEMMIU3VztuotcDNq4FhMz361gwjA9DW/Arcs2YPrALwP7NHYMlVwzz7BmYDkLcW+PFlQG+biC84Fpj+MDD514Aq2LPvR0QEiGMhHba1A6k80bpcEw1k3CyGkN7cYmiqAXJXArvfEuf3AoDYMcAV/wOMmuefoaS2qLXmo2BH6x+SdspgICVLrEVKvUz8/ckVHi8Gw8gA9WFuIf761VEAwGsLJ+CXmYmef5MWE3DwI+DHF4G6YnGZJgrI/h0w5V5AHer59ySigcXYABz/f+JtmIIdAGxfVQo1MPI68TbM0KsBRS/byLXVVCO2ldu9ShyHCQBiRomhZPR8r3xZe0x9GVDwI1CwXfx91RU5r1eogaSpYvhIuxxInNgnnRIYRgawv399DO/+VABVgBwf3TsNk1MjvfNGFrPYYGzHC0CtbfC1oAggawkw9TdAoNY770tE/ZPVIn6ZHvxEDCLmNiNMJ2eLNSCj5wFB4d4tR3MtsGuVGEyMOnFZ9Ajx9s2YG3wjlDTVONd8VJ10Xi9TiN2Y7eEjaaokt9QZRgYwi1XAb9fuw6Zj5YgMVuHLB7OREuXFWyiWFuDwZ8CO51u70gVqgUseBKb91vv/cRCRf2uuE2+R7HvP+XZC5FAxgIy7RRxmQKpy7Vop9tgBgOjhwOX/I05E2pehxKAHinJaw0f54Ys2kAEJ42zh4wog+RKfqKVmGBngmkwtWPDWLhw+r8OQmGCsfyAb4RovV8lZLcCR9WIoqcoXl6nDxEByyQPikPRERHYGna0Gos2XfWC4+EWfuRAYPNk3utsadMDut8XGroY6cVnUMFsoual3A0O2mMTeig3l4q2WhjLxub6sdVl9ma2x7kVf1zGjWms+UrJ98v9YhhFCha3L7wWdAdPSIvHhPdM80+W3O1YLcOwrMZRUHBOXqULEWzdZDwHBUd4vAxH5LoNOrHHIfaNNjYPtNsioub47lpFBL/a8yX2jdUTXyCFiKMm4xTmUmA22YFHeQcAobV1+ca+WrkQOaW1wmnY5EBLr2fPzAoYRAgCcKNPjpjdz0WBswY0TB+HFmzM91+W3O1YrcOJrYPtzrVWKymBgyj1iY1c/+CARkQcZ9GLj0ItDyJWP+34D0baM9eIYJTmvA8014rKIVCA8pbU2w16D4gq5UpxRPTQOCE2wvY5vfQ6NB0ITgZAYb5yNVzGMkMP2k5X49Zo9sFgFLLtmOB6ekd63BRAEcVCi7c8CpXnisoAgYNJd4jglsaP6tjxE1LcM+jY1IXXiMl9rENoTxgZxNNec1zqu4VCoW8NE22AREi8Gj5B4MXwERfhn92EXMIyQk3/vLsKfvzwCAHhlwXjMn+DioECeJAjizJnb/yFOzmc3aBIw4Q7xPjF74BD1HwY98PNb4kScjhAyXBzp1J9DyMVMjcDxrwEIzmEjMNw32rxIiGGE2nnm2+N4e8dZqBRyrL13GqamSdTYSRDEYZz3vAuc+g6wtojLAwKBUb8EJtwOpF7eb/9SIPKK+nLg/F5xzJ/ECdK2u+iobUV/DCHULYYRasdqFfDgv/dj49EyRGiUWP/gdKRFSzxqakOFOFbJgbXOIytqk4Hxt4mPiBTpykfkiwQBqDkLFOcCRblAcY74s51CLQaS5EvER9K0vulpYaxvvR1jDyFR6WIIGXsjQ8gAxDBCHWo2WXDr27k4eE6HtGixy29EsPdH4euWIADn94vDzR/+vHX0Q0BsNT7hTrGVPefBoYHIagHKj9rCR474bJ+80kEmzs/SVOU8Z4td9AhbOMkCkqcBEWmeu4VgrBdrQnJebxNChtlCSB+Px0E+hWGEOlVRb8ANK3Nwvq4ZU1Mj8eG9U6EO8KH/LMzN4v3XAx+KozHaqbXiX1cT7gQGTRzw92KpH2sxAhcOtAaP4t2tI4HayZXi5yA5SxxjImmaOMCgo9Zkl7hvye72o3MCYoPKpGmt4SR+nPtDq3fUq4QhhNpgGKEu5ZfV46Y3c1BvbMH88Yl4ecH4vuvy647aInFuirx/t86DA4h/AU64Axi3gF2EB4qmGmDvauDYBjGYRqSKj8i01teaKP8MqcZ6MTQU5YoB4vw+oMXgvI0qRBzSOzlbnOBs0CTXawobq8TjF+8SHxcOAFaz8zZKjTjIWJLt1s7gKUBgJ//fGhva1ITYQkjk0NYQ0ptBwKhfYRihbv14qhKL3xO7/D4yIx2/v2a41EXqnNUqzsOQ929xQDX7f9TyACB9ttjoNX2WZyfNupggiK3mDXViAz3t4M7/sybPqTkrzhFyYK3zXCUdUYXagklKa0CJSBMDizapTyYGc0lDpdjOw97eo+wwIFidt9FEi6HDHj7iMjz3JW9uFgOJPZyU7G4/LoZMDsSNaQ0nyVlib7c9/wJ2vnZRCPlD70cipX6JYYRc8vHPxVi+XhyQ7KVbMnHjxMESl8gFBp047PyBtWLvAbvgGLGmZMIdXY9dYrWIx2iutT3q2ryuFf9Tbvtz2/UX/zUZkSbOBxE/TpyCO36c2KXPFzXXApUnxaH6ZQpgxByfHD7aoeRn8S/vE1+3flHHZQDT7hdrBGoKgNpC26MA0F9Au+GyncjEAOkIK2mtYSUiVfxddFerYrUCLc2AqQkwN9qem8SQ6vTc2fom8ZZJ9an2xw5Pbg0eydlAdHrf1fJYreK/C/stoeLc9rO+AoBCBVhM4uvIIbaaEIYQ6hzDCLnsH/89gVXbz0CpkGHtPdMwbYgfDddecUJs9HpwHdBY0bp80CQxGBjqLgobde3vvbtLrgTUIa0N9S4WEmcLJ+Nanz3ZWLArgiA2bKzMFx9V9ueT7Rs8ygOAYTPFL5MRc8RzkprVApz4RuyNUbK7dfmwa4Dsh8QJwDr7PZoNgK5EDCdOQaVQDCvd1aqow8SQEhIv1rx1FCq6O4Y7Yke3tvdIzgK0Eoz90xV9KVCyqzWclB0GBItt+PM/ABk3M4RQtxhGyGVWq4CHPt6Pbw+XQRukxPoHszE0xge+mNxhMYsDquX9Gzi5sXXskq6oQsWRD4PCL3q2PQIv+tm+XqkRvxCbaoCyQ0Dpodbn6lPtq9sB8YsuPsM5pMSM6PltJatV/Mu16uRFweNk12ErNBGIGQ40VjvP+qnUiIEk42Zg6Iy+v51hagTyPgJyV4rBARD/Ch93izifUW9H6RUEsYeJPZxcHFbqL7h/zIAgQKURpzhQacTfoSrY9tzJcmUQEDZIbPvhy7VSHTE2iO22ooczhJDLGEbILQazBbe+vQt5JXVIidLgywenI9IXuvz2REMlcHS9GBY6ChNBEeK9b2+0LzE1AuXHgLKDQOlBMaBUHGut2m5LoRa/ZNve5okbI35x2bWYgJozrbUb9tBRdap9A0c7mVy87RA9QgweMSPF19Hpzm1cKvPFbtSHP2sNAIAYwkbPE4NJynTvDj5XXy42hNz7bmtNU2A4MOVecWLFvrrlZW4Wv2hrC8Wxb5RB3YQKDQflI3IBwwi5rbLeiBv+uRPnapsxOSUCa++dhkAlu+b1msUsfvG3rUUpO+w8loqDTAwN4Sm2v+DPilXjHVGoxAGlYoY7B4/IoYAy0PXy2cd4OfI5cOQL59s5oYlid+qMm4CE8Z671VRxXLwVc+jT1qAWkSrWgoy/zTmQEZHfYhihHjlVXo8b38xBvaEFczMT8eqC8ZDL/bCrpK+zWoG6QudbPGWHOhjICmKXzpgRrYEjeoT4c3iK56vLrRag8CextuTYf5xv+UQNE9uXZNwkBiZ3CYI4bkzOG8DpTa3LB08VZ3EeeT3HpSDqZxhGqMd2nq7CXat/RotVwC/GJWDFjRkIDfRil1lqVV8uhhJdSeutlrBEacbOaDECpzeLwSR/o9iLxC5hvBhKxtzYfcNLixk4+qU4s2mZvZ2KTBxRN/t3YvsJIuqXGEaoV77Ydw5/+OIQLFYBKVEavLFwIjIGc0bdActYD5z4VryVc3pLm1tHMrFdScZNYjuTto0yDTpg3xpxrhL9eXGZUiN2vb7kAbFXBhH1awwj1Gv7imrw8Md5OF/XDKVChj9dNwqLs1N9c6RW6juNVeIoqIe/EAfssrN3FR5zg3jbaf8HgKleXBccK44PMvnX/teLhIh6jGGEPKKuyYT/+fwQNh0T2zLMGh2H524ah3CNn/a0Ic+qKxF7Lh3+rM0tmDZiRoq3YjJulnZKeyKSBMMIeYwgCHg/pxDPfHsCJosVg8KD8NrC8ZiUwr9wqQ17V+H8/4rzBV3yIDBshn/OFUNEHsEwQh53+JwOD328H0XVTVDIZXhs1gjcf/kQ9rYhIqIOufr9zVF7yGUZg7X4+neXYm5mIixWAc9uPIHFa/agqsEoddGIiMiPMYyQW0IDlXjt1vH4x40ZCFTKseNkJea8+iNyTldJXTQiIvJTDCPkNplMhlunJuOrJZciPTYElfVG3P7ubry06SQsVp+/60dERD6GYYR6bER8KL56aDpumTwYggC8tuUUbvvXLpTpOpkzhYiIqAMMI9QrGlUAnrspE6/eOh7BKgV2F9Tgutd+xNYTFVIXjYiI/ESPwsjKlSuRmpqKwMBATJs2DT///HOn265ZswYymczpERjoxiRe5BfmjR+Erx++DKMTwlDTaMLda/ZgxbfHYbZYpS4aERH5OLfDyLp167Bs2TI8+eST2L9/PzIzMzF79mxUVHT+l3BYWBhKS0sdj6Kiol4VmnxTWnQw1j+YjbuyUgAAb+04i5tX5aKkpknikhERkS9zO4y89NJLuO+++3D33Xdj9OjRWLVqFTQaDVavXt3pPjKZDPHx8Y5HXFxcrwpNvitQqcDf5o3FqjsmIiwwAHkldbjutR+x8Uip1EUjIiIf5VYYMZlM2LdvH2bOnNl6ALkcM2fORG5ubqf7NTQ0ICUlBUlJSZg3bx6OHj3a5fsYjUbo9XqnB/mXa8cm4JuHL8OE5HDUG1rw27X78cRXR2AwW7rfmYiIBhS3wkhVVRUsFku7mo24uDiUlZV1uM+IESOwevVqfPXVV1i7di2sViuys7Nx7ty5Tt9nxYoV0Gq1jkdSUpI7xSQfkRSpwaf3Z+H+K8TZWT/ILcKN/8zB2coGiUtGRES+xOu9abKysrBo0SKMHz8eV1xxBdavX4+YmBi89dZbne6zfPly6HQ6x6OkpMTbxSQvUSrkWD5nFN67ewoig1U4VqrHL17/CRsOnJe6aERE5CPcCiPR0dFQKBQoLy93Wl5eXo74+HiXjqFUKjFhwgScPn26023UajXCwsKcHuTfrhoRi/8+chkuGRKJJpMFS9fl4dFPD6KynkPJExENdG6FEZVKhUmTJmHLli2OZVarFVu2bEFWVpZLx7BYLDh8+DASEhLcKyn5vbiwQPz73kuwdGY6ZDLgi/3ncPlzW/HsxhOoazJJXTwiIpKI27dpli1bhn/96194//33cfz4cTzwwANobGzE3XffDQBYtGgRli9f7tj+6aefxvfff4+zZ89i//79uOOOO1BUVIR7773Xc2dBfkMhl2HpzOFY95ssZCaFo9lswZvbzuCyZ7fi1c2nUG8wS11EIiLqYwHu7rBgwQJUVlbiiSeeQFlZGcaPH4+NGzc6GrUWFxdDLm/NOLW1tbjvvvtQVlaGiIgITJo0CTk5ORg9erTnzoL8ztS0SGx4MBubj1fgxe/zcaKsHi9vPon3cgrw2yuGYlFWCjQqt/95EhGRH5IJguDzM5vp9XpotVrodDq2H+mHrFYB3x4pxUubTuJsZSMAIDpEjYeuGoqF05KhDlBIXEIiIuoJV7+/GUbIZ7RYrNiQdwGvbjmJkppmAECiNhC/m5GOmyYNhlLBqZSIiPwJwwj5LVOLFZ/tK8HrW06jTC/OAJwSpcHSmen4ZeYgKOQyiUtIRESuYBghv2cwW/Dv3cV4c9tpVDWIvW2GxYZg2TXDce2YeMgZSoiIfBrDCPUbjcYWvJ9biLe2n4WuWextMyYxDI/OGo6rRsRCJmMoISLyRQwj1O/oDWa882MBVv9UgAZjCwBgQnI4Hps1AtOHRUtcOiIiuhjDCPVbNY0mvLXjDN7PKYTBbAUAZA2JwqOzhmNyaqTEpSMiIjuGEer3KuoN+OfWM/hodzFMFjGUXDkiBo9eMwIZg7USl46IiBhGaMA4X9eMN344hU/3noPFKv5znj0mDsuuGYER8aESl46IaOBiGKEBp7CqEa9uOYUNeechCIBMBlyXkYClM9KRHsdQQkTU1xhGaMA6VS4OLf/t4TIAYiiZOy4RD89Ix7DYEIlLR0Q0cDCM0IB37IIer245ie+OlgMA5DJg3vhBeHhGOtKigyUuHRFR/8cwQmRz5LwOr2w+hc3HxVCikMswf/wgPDxjGFKiGEqIiLyFYYToIofO1eGVzafww4kKAGIo+dXEQfjd1elIitRIXDoiov6HYYSoE3kldXh500lsP1kJAAiQy3Dz5MFYctUwDI5gKCEi8hSGEaJu7CuqxSubT+LHU1UAAKVChlsmJ2HJVcOQGB4kcemIiPwfwwiRi/YW1uDlzSex83Q1AEClkOPWqUl48MphiNcGSlw6IiL/xTBC5KbdZ6vx0qaT2F1QAwBQBchx29RkPHjlUMSGMZQQEbmLYYSoh3LOVOHlTSexp7AWAKAOkOOOS1Lw2yuGIiZULXHpiIj8B8MIUS8IgoCdp6vx8uaT2FckhpJApRyLslLxm8uHIDqEoYSIqDsMI0QeIAgCdpwSa0rySuoAAEFKBRZlp+CeS9MQG8rbN0REnWEYIfIgQRCwLb8SL28+iUPndADEcUquHhmLBZOTcOWIGAQo5BKXkojItzCMEHmBIAjYcrwCb24/47h9AwCxoWr8atJg3DI5iUPNExHZMIwQednpinqs21OC9fvPo7rR5Fg+LS0SC6YkYc7YBASpFBKWkIhIWgwjRH3E1GLFDyfK8cmeEuw4WQmr7RMVGhiAeeMTsWByMsYOCoNMJpO2oEREfYxhhEgCpbpmfL73HNbtLcG52mbH8lEJYbh1ShLmjx8ErUYpYQmJiPoOwwiRhKxWAblnq7FuTwk2Hi2DqcUKQBxI7dox8VgwJQlZQ6Igl7O2hIj6L4YRIh9R12TChgPnsW7vORwv1TuWJ0UG4ZZJSbhp8mAkaDkXDhH1PwwjRD5GEAQcOa/HJ3uK8Z+8C6g3tgAA5DLg8uExuHVKEq4eGQdVALsIE1H/wDBC5MOaTRZ8e7gU6/aW4GfbXDgAEBWswo0TB2HBlCQMiw2VsIRERL3HMELkJ85WNuDTvefwxf5zqKw3OpYPiw3BjFGxuGZUHCYkR0DB9iVE5GcYRoj8jNlixbb8SqzbU4Jt+RVosbZ+NCODVbhqRCxmjorFZcNjEKIOkLCkRESuYRgh8mO6ZjO2n6zEluPl2HqiAnpDi2OdSiHHJUOjMHNULGaMisOgcDZ+JSLfxDBC1E+YLVbsLazF5uPl2Hy8HEXVTU7rRyWE4RpbMMkYpGV3YSLyGQwjRP2QIAg4U9mAzccrsOV4OfYV1aLN3RzEhqoxY1QsZo6Kw/Rh0QhUcjh6IpIOwwjRAFDTaMLWExXYcqIc2/Mr0WiyONYFKuW4dFg0Zo6Kw9WjYhEbGihhSYloIGIYIRpgjC0W7D5bg83Hy7HleAXO1zU7rc9MCsfMkbGYOToOI+NDOVcOEXkdwwjRACYIAo6X1mPL8XJsPlGBgyV1TusTtYG4fHgMLh8eg+lDozlfDhF5BcMIETlU6A344UQFNh8vx0+nq2AwWx3r5DKx1uTydDGcZA7WIkDBUWCJqPcYRoioQ80mC3YXVGPHySrsOFWJ0xUNTuvDAgNwaXo0Lk+PwWXDY9h1mIh6jGGEiFxyoa4ZP56qxI6TVfjpdBV0zWan9UNjgh23dC5Ji0KQij10iMg1DCNE5DaLVcDBc3XYcbISO05WIq+kzqnrsCpAjqmpkbgsPRqXD49hQ1gi6hLDCBH1mq7ZjJzT4u2cHSer2vXQiQ1V47L0GFw+PBqXDotGVIhaopISkS9iGCEijxIHXGu03dKpxK6zNWg2t45rIpMBYxO1tmASgwnJ4Rx0jWiAYxghIq8ytliwt7AWO05WYvvJSpwoq3darw6QY3JqBLKHRiN7aBQyBrGXDtFAwzBCRH2qQm/Aj6fEWzo5Z6pRWW90Wh+iDsC0tEhkDY1C9tBojIwP5Tw6RP0cwwgRScY+h07OmWrknK5G7tnqdr10IjRKZA2NQpat5mRIdDAbwxL1MwwjROQzLFYBx0v1yD1TjZwzVfi5oMZpHh0AiAtTI3totK3mJAqDIzQSlZaIPIVhhIh8ltlixaFzdcg5XY2cM9XYV1wLU4vVaZvkSA2yh0bZak+iONEfkR9iGCEiv2EwW7C/qFa8rXOmCgfP6WCxOv/XlB4bYgsn0ZiSGsFuxER+gGGEiPxWg7EFewpqkHOmCjlnqnGsVI+L/6caEh2MSSkRmJwagUkpkRgawzYnRL6GYYSI+o3aRhN2F4i3dHLPVOPURfPpAGKD2EkpYjCZnBqBjEFajnNCJDGGESLqt+qaTNhfXIu9hbXYW1SLgyV1MF7U5kSpkGHsIC0mtwko0by1Q9SnGEaIaMAwtVhx9IIO+4paA0pVg7HddqlRGkcwmZwSgaExIRzrhMiLGEaIaMASBAHFNU3YW1iLfcW12FdYi5MV9e3anWiD7Ld2xEfm4HDOSkzkQQwjRERt6JrN2G8LJnuLapBXUgeD2fnWToBchhHxoYgNVSMyWI3IYGXHzxoVwoIC2GCWqBsMI0REXTBbrDh2QY+9RbXYV1SDvYW1qKhvf2unMwFyGcI1KkQFqxARrERUsBoRjrCiRGSIGFoig8VHRLAS6gDWutDAwjBCROQGQRBwrrYZJ8rqUdNoRE2j2fm5SXyubTSjwdjSo/cIUQdgcEQQJiSLt4UmJocjjcPgUz/GMEJE5CUGswV1TWZU28KJ+GxCTaMJNU22Z8fDjNomU7tB3Owig1WYkBSOiSkRmJgcgcwkLTSqgD4+IyLvYBghIvIRVquAekMLqhuNOFnegAPFtdhXVItD53XthsFXyGUYlRCKSckRjoAyOCKItSfklxhGiIh8nL1L8v7iOuwvEgNKmd7QbruYULUtnIRjUkoExiRyQDfyDwwjRER+6EJds9jrp6gW+4vrcPS8Di0X3eJRKeQYMygMEx1tTyIQr+VEguR7GEaIiPoBg9mCw+fFAd32F9Vif3EtqhpM7bYbFB6ECcnhSI0KRrhGiQhbTx776wiNCqGBARzkjfqUq9/fbCVFROTDApUKTEmNxJTUSACtA7o5ak+K6nCiTI/zdc04X9fc5bEUchnCg5SOgBKuUSEyuPV1hEZpW9b6OlyjhFIh74tTpQGMNSNERH6uwdiCQyV1OFBShwq9AbVNYg+e2iYTahvNqGsyodFk6fHxQ9UBiAhWISJYhYSwQAyKCMKg8CAkhgdhsO11uEbJRrbUDm/TEBGRg7FF7I5sDyj2sFLXZEZto8kpwNi30zWb2w2h3xmNSoHE8PYhJTE8CIMighAXqkZAH9ewWKwCGk0taDC0oNHYAqVCjuhQNYJVCganPsLbNERE5KAOUCAuTIG4MNcbulqsAnTNZltAMaGqwYRS2+0g8WHA+dpmVDUY0WSy4HRFA05XNHR4LIVchviwQAyyhZPE8EAMCtfYalnE10EqBSxWAQ1GMTw0GltQb3tuMLSgwdjiWOe83CK+vmhdUye1QUFKBWJC1eIjRN362vZztO11dIiKo+b2EYYRIiLqkEIucwxn3xWD2YJSnRhMLtQ141xds+P1+bpmlOqaYbYIre1aCjs+TqBS3m6+IE8IkMsQEhgAc4sVjSYLms0WFNc0obimqdt9tUHKDkNLdIhzmIkMVkHBxsE9xjBCRES9EqhUIC06GGnRwR2ut1gFVDUYca5WDCMXbGGl7et6Y4tTEFEp5AhWKxASGIBgVQBCAwMQrBYfobbnENsjWB2AkMAAhKgVCFErxf3arFMHyB23ZRqNLahqMKKy3vawvXZaZltutog1Q7pmc6c1PnZyGRAdoka8NhBxYYGIDwu86LUacWGBCA1Ueu4X34+wzQgREUlO12yGvtlsCxwKyW+PCIIYRKoajKiobx9exABjQmW9EdWNRpfb1gSrFIjT2gJKWKDjdZwtvMSHBSI6RNXn7Wu8hW1GiIjIb2iDlNAG+U6tgUwms3VtVmFYbGiX27ZYrKhpNKFcb0SZ3oAyvQHlOtuz3oAy2+t6QwsaTRacrWzE2crGTo8nl4mj7rYNKbGhamhUAQhSKRCkVCBQKUegUnwdpFI4Xgfafw6Q+1Wg6VEYWblyJZ5//nmUlZUhMzMTr7/+OqZOndrp9p999hn++te/orCwEOnp6Xj22Wdx3XXX9bjQREREviJAIUdsWCBiwwKRAW2n2zUaW8Rw4ggpRqewUq43oKLeCItVQLneiHK9EYCux+VSKmROgSVIqYBaqUCQUt4aYgIUCLStuysrFclRmh6/X2+4HUbWrVuHZcuWYdWqVZg2bRpeeeUVzJ49G/n5+YiNjW23fU5ODhYuXIgVK1bgF7/4BT766CPMnz8f+/fvx9ixYz1yEkRERL4uWB2AITEhGBIT0uk2FquA6gZbDYvO4AgvlfVijyWD2QqDWWyE22yywNBigcHWKLfZbHFqd2O2CDBbWlBvaHGpfNePS5AsjLjdZmTatGmYMmUK3njjDQCA1WpFUlISfve73+GPf/xju+0XLFiAxsZGfP31145ll1xyCcaPH49Vq1a59J5sM0JERNQ9QRBgbLGi2WQPJ22eTW2CjG2ZfXmz2YLF2aken+PIK21GTCYT9u3bh+XLlzuWyeVyzJw5E7m5uR3uk5ubi2XLljktmz17NjZs2NDp+xiNRhiNRsfPer3enWISERENSDKZeGsmUKlAhNSFcYNbrVuqqqpgsVgQFxfntDwuLg5lZWUd7lNWVubW9gCwYsUKaLVaxyMpKcmdYhIREZEf8cmmtsuXL4dOp3M8SkpKpC4SEREReYlbt2mio6OhUChQXl7utLy8vBzx8fEd7hMfH+/W9gCgVquhVqvdKRoRERH5KbdqRlQqFSZNmoQtW7Y4llmtVmzZsgVZWVkd7pOVleW0PQBs2rSp0+2JiIhoYHG7a++yZctw1113YfLkyZg6dSpeeeUVNDY24u677wYALFq0CIMGDcKKFSsAAI888giuuOIKvPjii7j++uvxySefYO/evXj77bc9eyZERETkl9wOIwsWLEBlZSWeeOIJlJWVYfz48di4caOjkWpxcTHk8tYKl+zsbHz00Uf4y1/+gj/96U9IT0/Hhg0bOMYIERERAeDcNEREROQlrn5/+2RvGiIiIho4GEaIiIhIUgwjREREJCmGESIiIpIUwwgRERFJimGEiIiIJOX2OCNSsPc+5uy9RERE/sP+vd3dKCJ+EUbq6+sBgLP3EhER+aH6+npotdpO1/vFoGdWqxUXLlxAaGgoZDKZx46r1+uRlJSEkpKSATGY2kA6X55r/zWQzpfn2n8NlPMVBAH19fVITEx0Gp39Yn5RMyKXyzF48GCvHT8sLKxf/2O42EA6X55r/zWQzpfn2n8NhPPtqkbEjg1YiYiISFIMI0RERCSpAR1G1Go1nnzySajVaqmL0icG0vnyXPuvgXS+PNf+a6Cdb3f8ogErERER9V8DumaEiIiIpMcwQkRERJJiGCEiIiJJMYwQERGRpPp9GFm5ciVSU1MRGBiIadOm4eeff+5y+88++wwjR45EYGAgMjIy8O233/ZRSXtnxYoVmDJlCkJDQxEbG4v58+cjPz+/y33WrFkDmUzm9AgMDOyjEvfcU0891a7cI0eO7HIff72uqamp7c5VJpNhyZIlHW7vb9d0x44dmDt3LhITEyGTybBhwwan9YIg4IknnkBCQgKCgoIwc+ZMnDp1qtvjuvu57wtdnavZbMbjjz+OjIwMBAcHIzExEYsWLcKFCxe6PGZPPgt9obvrunjx4nblvvbaa7s9ri9eV6D78+3oMyyTyfD88893ekxfvbbe0q/DyLp167Bs2TI8+eST2L9/PzIzMzF79mxUVFR0uH1OTg4WLlyIe+65BwcOHMD8+fMxf/58HDlypI9L7r7t27djyZIl2LVrFzZt2gSz2YxZs2ahsbGxy/3CwsJQWlrqeBQVFfVRiXtnzJgxTuX+6aefOt3Wn6/rnj17nM5z06ZNAICbb76503386Zo2NjYiMzMTK1eu7HD9c889h9deew2rVq3C7t27ERwcjNmzZ8NgMHR6THc/932lq3NtamrC/v378de//hX79+/H+vXrkZ+fj1/+8pfdHtedz0Jf6e66AsC1117rVO6PP/64y2P66nUFuj/ftudZWlqK1atXQyaT4Ve/+lWXx/XFa+s1Qj82depUYcmSJY6fLRaLkJiYKKxYsaLD7W+55Rbh+uuvd1o2bdo04f777/dqOb2hoqJCACBs3769023ee+89QavV9l2hPOTJJ58UMjMzXd6+P13XRx55RBg6dKhgtVo7XO+v11QQBAGA8OWXXzp+tlqtQnx8vPD88887ltXV1QlqtVr4+OOPOz2Ou597KVx8rh35+eefBQBCUVFRp9u4+1mQQkfnetdddwnz5s1z6zj+cF0FwbVrO2/ePOHqq6/ucht/uLae1G9rRkwmE/bt24eZM2c6lsnlcsycORO5ubkd7pObm+u0PQDMnj270+19mU6nAwBERkZ2uV1DQwNSUlKQlJSEefPm4ejRo31RvF47deoUEhMTMWTIENx+++0oLi7udNv+cl1NJhPWrl2LX//6111OGOmv1/RiBQUFKCsrc7p2Wq0W06ZN6/Ta9eRz76t0Oh1kMhnCw8O73M6dz4Iv2bZtG2JjYzFixAg88MADqK6u7nTb/nRdy8vL8c033+Cee+7pdlt/vbY90W/DSFVVFSwWC+Li4pyWx8XFoaysrMN9ysrK3NreV1mtVixduhTTp0/H2LFjO91uxIgRWL16Nb766iusXbsWVqsV2dnZOHfuXB+W1n3Tpk3DmjVrsHHjRrz55psoKCjAZZddhvr6+g637y/XdcOGDairq8PixYs73cZfr2lH7NfHnWvXk8+9LzIYDHj88cexcOHCLidRc/ez4CuuvfZafPDBB9iyZQueffZZbN++HXPmzIHFYulw+/5yXQHg/fffR2hoKG688cYut/PXa9tTfjFrL7lnyZIlOHLkSLf3F7OyspCVleX4OTs7G6NGjcJbb72Fv//9794uZo/NmTPH8XrcuHGYNm0aUlJS8Omnn7r014a/evfddzFnzhwkJiZ2uo2/XlNqZTabccstt0AQBLz55ptdbuuvn4Vbb73V8TojIwPjxo3D0KFDsW3bNsyYMUPCknnf6tWrcfvtt3fbsNxfr21P9duakejoaCgUCpSXlzstLy8vR3x8fIf7xMfHu7W9L3rooYfw9ddfY+vWrRg8eLBb+yqVSkyYMAGnT5/2Uum8Izw8HMOHD++03P3huhYVFWHz5s2499573drPX68pAMf1cefa9eRz70vsQaSoqAibNm1ye2r57j4LvmrIkCGIjo7utNz+fl3tfvzxR+Tn57v9OQb899q6qt+GEZVKhUmTJmHLli2OZVarFVu2bHH6y7GtrKwsp+0BYNOmTZ1u70sEQcBDDz2EL7/8Ej/88APS0tLcPobFYsHhw4eRkJDghRJ6T0NDA86cOdNpuf35utq99957iI2NxfXXX+/Wfv56TQEgLS0N8fHxTtdOr9dj9+7dnV67nnzufYU9iJw6dQqbN29GVFSU28fo7rPgq86dO4fq6upOy+3P17Wtd999F5MmTUJmZqbb+/rrtXWZ1C1ovemTTz4R1Gq1sGbNGuHYsWPCb37zGyE8PFwoKysTBEEQ7rzzTuGPf/yjY/udO3cKAQEBwgsvvCAcP35cePLJJwWlUikcPnxYqlNw2QMPPCBotVph27ZtQmlpqePR1NTk2Obi8/3b3/4mfPfdd8KZM2eEffv2CbfeeqsQGBgoHD16VIpTcNmjjz4qbNu2TSgoKBB27twpzJw5U4iOjhYqKioEQehf11UQxF4DycnJwuOPP95unb9f0/r6euHAgQPCgQMHBADCSy+9JBw4cMDRg+Qf//iHEB4eLnz11VfCoUOHhHnz5glpaWlCc3Oz4xhXX3218Prrrzt+7u5zL5WuztVkMgm//OUvhcGDBwt5eXlOn2Gj0eg4xsXn2t1nQSpdnWt9fb3w2GOPCbm5uUJBQYGwefNmYeLEiUJ6erpgMBgcx/CX6yoI3f87FgRB0Ol0gkajEd58880Oj+Ev19Zb+nUYEQRBeP3114Xk5GRBpVIJU6dOFXbt2uVYd8UVVwh33XWX0/affvqpMHz4cEGlUgljxowRvvnmmz4ucc8A6PDx3nvvOba5+HyXLl3q+N3ExcUJ1113nbB///6+L7ybFixYICQkJAgqlUoYNGiQsGDBAuH06dOO9f3pugqCIHz33XcCACE/P7/dOn+/plu3bu3w3639nKxWq/DXv/5ViIuLE9RqtTBjxox2v4eUlBThySefdFrW1edeKl2da0FBQaef4a1btzqOcfG5dvdZkEpX59rU1CTMmjVLiImJEZRKpZCSkiLcd9997UKFv1xXQej+37EgCMJbb70lBAUFCXV1dR0ew1+urbfIBEEQvFr1QkRERNSFfttmhIiIiPwDwwgRERFJimGEiIiIJMUwQkRERJJiGCEiIiJJMYwQERGRpBhGiIiISFIMI0RERCQphhEiIiKSFMMIERERSYphhIiIiCTFMEJERESS+v9Q/IzHZTT0rAAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(history.history[\"loss\"], label = \"train\")\n",
    "plt.plot(history.history[\"val_loss\"], label = \"test\")\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "499bb7d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "214/214 [==============================] - 1s 3ms/step - loss: 0.0834 - accuracy: 0.9868\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.0833858922123909, 0.9868382811546326]"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(X_train_seq_RA, y_train_seq_RA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "344fddd3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "72/72 [==============================] - 0s 5ms/step - loss: 0.6664 - accuracy: 0.8679\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.6664052605628967, 0.867866575717926]"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(X_test_seq_RA, y_test_seq_RA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "d58f6e97",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "72/72 [==============================] - 0s 6ms/step - loss: 0.6664 - accuracy: 0.8679\n",
      "model saved at  C:\\datasets/RA_Model.h5\n",
      "Accuracy >86.786658\n",
      "Base Loss >0.67\n"
     ]
    }
   ],
   "source": [
    "base_loss,base_accuracy=model.evaluate(X_test_seq_RA, y_test_seq_RA)\n",
    "\n",
    "model_file='C:\\datasets/RA_Model.h5'\n",
    "  \n",
    "tf.keras.models.save_model(model, model_file, include_optimizer=False)\n",
    "print('model saved at ', model_file)\n",
    "#score,keras_file=evaluate_model(trainX,trainy,testX,testy)\n",
    "score=base_accuracy*100\n",
    "print('Accuracy >{:f}'.format(score))\n",
    "print('Base Loss >{:.2f}'.format(base_loss))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "7d60865c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build CNN model using keras. For model building suggestions, referenced:\n",
    "# https://machinelearningmastery.com/deep-learning-models-for-human-activity-recognition/\n",
    "# https://machinelearningmastery.com/how-to-choose-loss-functions-when-training-deep-learning-neural-networks/\n",
    "# https://machinelearningmastery.com/how-to-develop-convolutional-neural-network-models-for-time-series-forecasting/\n",
    "\n",
    "# Sequential model type\n",
    "model2 = Sequential()\n",
    "model2.add(LSTM(units=128, input_shape = (n_timesteps,n_features)))\n",
    "model2.add(Dense(128, activation='relu'))\n",
    "model2.add(Dense(n_outputs, activation='softmax'))\n",
    "model2.compile(optimizer='adam', metrics=['accuracy'], loss='categorical_crossentropy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "84499d59",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " lstm_1 (LSTM)               (None, 128)               93696     \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 128)               16512     \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 19)                2451      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 112,659\n",
      "Trainable params: 112,659\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model2.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "130b1ee4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "193/193 [==============================] - 7s 14ms/step - loss: 1.9964 - accuracy: 0.3611 - val_loss: 1.2688 - val_accuracy: 0.5556\n",
      "Epoch 2/20\n",
      "193/193 [==============================] - 2s 11ms/step - loss: 1.0012 - accuracy: 0.6828 - val_loss: 0.8805 - val_accuracy: 0.7208\n",
      "Epoch 3/20\n",
      "193/193 [==============================] - 2s 9ms/step - loss: 0.7109 - accuracy: 0.7907 - val_loss: 0.6888 - val_accuracy: 0.8056\n",
      "Epoch 4/20\n",
      "193/193 [==============================] - 2s 10ms/step - loss: 0.5539 - accuracy: 0.8367 - val_loss: 0.5918 - val_accuracy: 0.8348\n",
      "Epoch 5/20\n",
      "193/193 [==============================] - 1s 5ms/step - loss: 0.4357 - accuracy: 0.8749 - val_loss: 0.5606 - val_accuracy: 0.8465\n",
      "Epoch 6/20\n",
      "193/193 [==============================] - 2s 9ms/step - loss: 0.3611 - accuracy: 0.8913 - val_loss: 0.5153 - val_accuracy: 0.8640\n",
      "Epoch 7/20\n",
      "193/193 [==============================] - 1s 7ms/step - loss: 0.3023 - accuracy: 0.9103 - val_loss: 0.5011 - val_accuracy: 0.8611\n",
      "Epoch 8/20\n",
      "193/193 [==============================] - 1s 6ms/step - loss: 0.2652 - accuracy: 0.9222 - val_loss: 0.5183 - val_accuracy: 0.8655\n",
      "Epoch 9/20\n",
      "193/193 [==============================] - 2s 11ms/step - loss: 0.2134 - accuracy: 0.9363 - val_loss: 0.4842 - val_accuracy: 0.8874\n",
      "Epoch 10/20\n",
      "193/193 [==============================] - 2s 8ms/step - loss: 0.1782 - accuracy: 0.9446 - val_loss: 0.4819 - val_accuracy: 0.8743\n",
      "Epoch 11/20\n",
      "193/193 [==============================] - 2s 8ms/step - loss: 0.1524 - accuracy: 0.9550 - val_loss: 0.4999 - val_accuracy: 0.8728\n",
      "Epoch 12/20\n",
      "193/193 [==============================] - 2s 9ms/step - loss: 0.1247 - accuracy: 0.9646 - val_loss: 0.5227 - val_accuracy: 0.8801\n",
      "Epoch 13/20\n",
      "193/193 [==============================] - 2s 8ms/step - loss: 0.1075 - accuracy: 0.9686 - val_loss: 0.5068 - val_accuracy: 0.8728\n",
      "Epoch 14/20\n",
      "193/193 [==============================] - 3s 14ms/step - loss: 0.0876 - accuracy: 0.9751 - val_loss: 0.5508 - val_accuracy: 0.8860\n",
      "Epoch 15/20\n",
      "193/193 [==============================] - 2s 9ms/step - loss: 0.0710 - accuracy: 0.9815 - val_loss: 0.5370 - val_accuracy: 0.8830\n",
      "Epoch 16/20\n",
      "193/193 [==============================] - 2s 8ms/step - loss: 0.0538 - accuracy: 0.9885 - val_loss: 0.5657 - val_accuracy: 0.8684\n",
      "Epoch 17/20\n",
      "193/193 [==============================] - 2s 11ms/step - loss: 0.0467 - accuracy: 0.9898 - val_loss: 0.5776 - val_accuracy: 0.8611\n",
      "Epoch 18/20\n",
      "193/193 [==============================] - 1s 6ms/step - loss: 0.0435 - accuracy: 0.9896 - val_loss: 0.6000 - val_accuracy: 0.8772\n",
      "Epoch 19/20\n",
      "193/193 [==============================] - 2s 8ms/step - loss: 0.0359 - accuracy: 0.9914 - val_loss: 0.6123 - val_accuracy: 0.8713\n",
      "Epoch 20/20\n",
      "193/193 [==============================] - 1s 7ms/step - loss: 0.0578 - accuracy: 0.9818 - val_loss: 0.6470 - val_accuracy: 0.8640\n"
     ]
    }
   ],
   "source": [
    "history2 = model2.fit(X_train_seq_LA, y_train_seq_LA, epochs = 20, batch_size = 32, validation_split = 0.1, shuffle = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "1809955d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "214/214 [==============================] - 1s 7ms/step - loss: 0.1116 - accuracy: 0.9725\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.111616350710392, 0.972506582736969]"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model2.evaluate(X_train_seq_LA, y_train_seq_LA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "dbc5667b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "72/72 [==============================] - 0s 4ms/step - loss: 0.6005 - accuracy: 0.8705\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.600516676902771, 0.8705004453659058]"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model2.evaluate(X_test_seq_LA, y_test_seq_LA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "e8724ed4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "72/72 [==============================] - 0s 2ms/step - loss: 0.6005 - accuracy: 0.8705\n",
      "model saved at  C:\\datasets/LA_Model.h5\n",
      "Accuracy >87.050045\n",
      "Base Loss >0.60\n"
     ]
    }
   ],
   "source": [
    "base_loss,base_accuracy=model2.evaluate(X_test_seq_LA, y_test_seq_LA)\n",
    "\n",
    "model_file2='C:\\datasets/LA_Model.h5'\n",
    "  \n",
    "tf.keras.models.save_model(model2, model_file2, include_optimizer=False)\n",
    "print('model saved at ', model_file2)\n",
    "score=base_accuracy*100\n",
    "print('Accuracy >{:f}'.format(score))\n",
    "print('Base Loss >{:.2f}'.format(base_loss))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "de17bb50",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n"
     ]
    }
   ],
   "source": [
    "# Base 모델을 로드 (LA_Model.h5)\n",
    "from tensorflow.keras.models import load_model\n",
    "\n",
    "base_model = load_model(model_file2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "a61c93cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "72/72 [==============================] - 2s 2ms/step - loss: 0.6005 - accuracy: 0.8705\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.600516676902771, 0.8705004453659058]"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "base_model.compile(optimizer='adam', metrics=['accuracy'], loss='categorical_crossentropy')\n",
    "base_model.evaluate(X_test_seq_LA, y_test_seq_LA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "23d5b979",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "72/72 [==============================] - 0s 5ms/step - loss: 5.5064 - accuracy: 0.2392\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[5.5063862800598145, 0.2392449527978897]"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "base_model.evaluate(X_test_seq_RA, y_test_seq_RA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "268df87a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of layers in the base model:  3\n"
     ]
    }
   ],
   "source": [
    "print(\"Number of layers in the base model: \", len(base_model.layers))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "39d5c191",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Layer Type</th>\n",
       "      <th>Layer Name</th>\n",
       "      <th>Layer Trainable</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>&lt;keras.engine.sequential.Sequential object at ...</td>\n",
       "      <td>sequential_1</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>&lt;keras.layers.core.dense.Dense object at 0x000...</td>\n",
       "      <td>dense_4</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>&lt;keras.layers.core.dense.Dense object at 0x000...</td>\n",
       "      <td>dense_5</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          Layer Type    Layer Name  \\\n",
       "0  <keras.engine.sequential.Sequential object at ...  sequential_1   \n",
       "1  <keras.layers.core.dense.Dense object at 0x000...       dense_4   \n",
       "2  <keras.layers.core.dense.Dense object at 0x000...       dense_5   \n",
       "\n",
       "   Layer Trainable  \n",
       "0            False  \n",
       "1             True  \n",
       "2             True  "
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "display_layers = [(layer, layer.name, layer.trainable) for layer in new_model.layers]\n",
    "pd.DataFrame(display_layers, columns=['Layer Type', 'Layer Name', 'Layer Trainable'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "f5069ea9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_last_layers(model, num_layers_to_remove):\n",
    "    # 모델의 레이어를 하나씩 슬라이스해서 앞의 레이어만 가져옴\n",
    "    model_layers = model.layers[:-num_layers_to_remove]  # 마지막 레이어부터 지정된 갯수만큼 제외\n",
    "    new_model = models.Sequential(model_layers)  # 새로운 모델에 해당 레이어들만 추가\n",
    "    return new_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "c1ab155b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 출력층부터 1개의 레이어를 삭제\n",
    "new_base_model = remove_last_layers(base_model, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "b7bdb819",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_6\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " sequential_5 (Sequential)   (None, 128)               110208    \n",
      "                                                                 \n",
      " dense_8 (Dense)             (None, 64)                8256      \n",
      "                                                                 \n",
      " dense_9 (Dense)             (None, 19)                1235      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 119,699\n",
      "Trainable params: 9,491\n",
      "Non-trainable params: 110,208\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# 기존 모델의 층을 동결 (학습되지 않도록 설정)\n",
    "new_base_model.trainable = False\n",
    "\n",
    "# 새로운 모델을 정의\n",
    "new_model = Sequential()\n",
    "\n",
    "# 기존 모델을 추가\n",
    "new_model.add(new_base_model)\n",
    "\n",
    "# 새로운 완전연결층 추가\n",
    "new_model.add(layers.Dense(64, activation='relu'))  # 기존 출력층 앞의 레이어 대신 추가\n",
    "\n",
    "# 최종 출력층 추가 (예: 10개의 클래스)\n",
    "new_model.add(layers.Dense(19, activation='softmax'))\n",
    "\n",
    "new_model.compile(optimizer='adam', metrics=['accuracy'], loss='categorical_crossentropy')\n",
    "\n",
    "# 모델 요약 출력\n",
    "new_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "d9b1088e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "193/193 [==============================] - 5s 8ms/step - loss: 2.0517 - accuracy: 0.3775 - val_loss: 1.5533 - val_accuracy: 0.5029\n",
      "Epoch 2/20\n",
      "193/193 [==============================] - 2s 10ms/step - loss: 1.4830 - accuracy: 0.5299 - val_loss: 1.4117 - val_accuracy: 0.5468\n",
      "Epoch 3/20\n",
      "193/193 [==============================] - 1s 5ms/step - loss: 1.3642 - accuracy: 0.5650 - val_loss: 1.3265 - val_accuracy: 0.5673\n",
      "Epoch 4/20\n",
      "193/193 [==============================] - 1s 3ms/step - loss: 1.2957 - accuracy: 0.5860 - val_loss: 1.2912 - val_accuracy: 0.5906\n",
      "Epoch 5/20\n",
      "193/193 [==============================] - 2s 8ms/step - loss: 1.2472 - accuracy: 0.6007 - val_loss: 1.2557 - val_accuracy: 0.5936\n",
      "Epoch 6/20\n",
      "193/193 [==============================] - 1s 6ms/step - loss: 1.2066 - accuracy: 0.6121 - val_loss: 1.2151 - val_accuracy: 0.6082\n",
      "Epoch 7/20\n",
      "193/193 [==============================] - 1s 4ms/step - loss: 1.1708 - accuracy: 0.6199 - val_loss: 1.2211 - val_accuracy: 0.6140\n",
      "Epoch 8/20\n",
      "193/193 [==============================] - 1s 4ms/step - loss: 1.1399 - accuracy: 0.6355 - val_loss: 1.1945 - val_accuracy: 0.6257\n",
      "Epoch 9/20\n",
      "193/193 [==============================] - 1s 6ms/step - loss: 1.1144 - accuracy: 0.6435 - val_loss: 1.1996 - val_accuracy: 0.5994\n",
      "Epoch 10/20\n",
      "193/193 [==============================] - 2s 9ms/step - loss: 1.0835 - accuracy: 0.6523 - val_loss: 1.1625 - val_accuracy: 0.6213\n",
      "Epoch 11/20\n",
      "193/193 [==============================] - 1s 4ms/step - loss: 1.0664 - accuracy: 0.6620 - val_loss: 1.1497 - val_accuracy: 0.6360\n",
      "Epoch 12/20\n",
      "193/193 [==============================] - 1s 4ms/step - loss: 1.0441 - accuracy: 0.6620 - val_loss: 1.1495 - val_accuracy: 0.6374\n",
      "Epoch 13/20\n",
      "193/193 [==============================] - 1s 4ms/step - loss: 1.0286 - accuracy: 0.6716 - val_loss: 1.1740 - val_accuracy: 0.6404\n",
      "Epoch 14/20\n",
      "193/193 [==============================] - 1s 8ms/step - loss: 1.0122 - accuracy: 0.6758 - val_loss: 1.1301 - val_accuracy: 0.6462\n",
      "Epoch 15/20\n",
      "193/193 [==============================] - 1s 3ms/step - loss: 0.9874 - accuracy: 0.6887 - val_loss: 1.1357 - val_accuracy: 0.6404\n",
      "Epoch 16/20\n",
      "193/193 [==============================] - 1s 4ms/step - loss: 0.9788 - accuracy: 0.6856 - val_loss: 1.1376 - val_accuracy: 0.6301\n",
      "Epoch 17/20\n",
      "193/193 [==============================] - 2s 9ms/step - loss: 0.9647 - accuracy: 0.6948 - val_loss: 1.1202 - val_accuracy: 0.6389\n",
      "Epoch 18/20\n",
      "193/193 [==============================] - 1s 7ms/step - loss: 0.9459 - accuracy: 0.7012 - val_loss: 1.1438 - val_accuracy: 0.6433\n",
      "Epoch 19/20\n",
      "193/193 [==============================] - 1s 3ms/step - loss: 0.9357 - accuracy: 0.7028 - val_loss: 1.1045 - val_accuracy: 0.6623\n",
      "Epoch 20/20\n",
      "193/193 [==============================] - 1s 5ms/step - loss: 0.9226 - accuracy: 0.7004 - val_loss: 1.0739 - val_accuracy: 0.6535\n",
      "Model: \"sequential_6\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " sequential_5 (Sequential)   (None, 128)               110208    \n",
      "                                                                 \n",
      " dense_8 (Dense)             (None, 64)                8256      \n",
      "                                                                 \n",
      " dense_9 (Dense)             (None, 19)                1235      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 119,699\n",
      "Trainable params: 9,491\n",
      "Non-trainable params: 110,208\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "history3 = new_model.fit(X_train_seq_RA, y_train_seq_RA, epochs = 20, batch_size = 32, validation_split = 0.1, shuffle = True)\n",
    "\n",
    "new_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "24059f79",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "72/72 [==============================] - 0s 3ms/step - loss: 1.1211 - accuracy: 0.6392\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[1.1211203336715698, 0.6391571760177612]"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_model.evaluate(X_test_seq_RA, y_test_seq_RA)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed4c8ebb",
   "metadata": {},
   "source": [
    "### 미세조정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "8cc77aec",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_model.trainable = True\n",
    "new_model.compile(optimizer='adam', metrics=['accuracy'], loss='categorical_crossentropy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "680e7c0f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Layer Type</th>\n",
       "      <th>Layer Name</th>\n",
       "      <th>Layer Trainable</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>&lt;keras.engine.sequential.Sequential object at ...</td>\n",
       "      <td>sequential_5</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>&lt;keras.layers.core.dense.Dense object at 0x000...</td>\n",
       "      <td>dense_8</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>&lt;keras.layers.core.dense.Dense object at 0x000...</td>\n",
       "      <td>dense_9</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          Layer Type    Layer Name  \\\n",
       "0  <keras.engine.sequential.Sequential object at ...  sequential_5   \n",
       "1  <keras.layers.core.dense.Dense object at 0x000...       dense_8   \n",
       "2  <keras.layers.core.dense.Dense object at 0x000...       dense_9   \n",
       "\n",
       "   Layer Trainable  \n",
       "0            False  \n",
       "1             True  \n",
       "2             True  "
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "display_layers = [(layer, layer.name, layer.trainable) for layer in new_model.layers]\n",
    "pd.DataFrame(display_layers, columns=['Layer Type', 'Layer Name', 'Layer Trainable'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "d12b759d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "193/193 [==============================] - 6s 15ms/step - loss: 0.9213 - accuracy: 0.7059 - val_loss: 1.1116 - val_accuracy: 0.6520\n",
      "Epoch 2/20\n",
      "193/193 [==============================] - 1s 5ms/step - loss: 0.8977 - accuracy: 0.7138 - val_loss: 1.0776 - val_accuracy: 0.6579\n",
      "Epoch 3/20\n",
      "193/193 [==============================] - 1s 6ms/step - loss: 0.8903 - accuracy: 0.7111 - val_loss: 1.1122 - val_accuracy: 0.6506\n",
      "Epoch 4/20\n",
      "193/193 [==============================] - 1s 7ms/step - loss: 0.8807 - accuracy: 0.7186 - val_loss: 1.0824 - val_accuracy: 0.6579\n",
      "Epoch 5/20\n",
      "193/193 [==============================] - 1s 6ms/step - loss: 0.8699 - accuracy: 0.7192 - val_loss: 1.0895 - val_accuracy: 0.6652\n",
      "Epoch 6/20\n",
      "193/193 [==============================] - 1s 3ms/step - loss: 0.8624 - accuracy: 0.7176 - val_loss: 1.0890 - val_accuracy: 0.6594\n",
      "Epoch 7/20\n",
      "193/193 [==============================] - 2s 9ms/step - loss: 0.8540 - accuracy: 0.7226 - val_loss: 1.0862 - val_accuracy: 0.6594\n",
      "Epoch 8/20\n",
      "193/193 [==============================] - 1s 7ms/step - loss: 0.8418 - accuracy: 0.7288 - val_loss: 1.0989 - val_accuracy: 0.6637\n",
      "Epoch 9/20\n",
      "193/193 [==============================] - 1s 3ms/step - loss: 0.8376 - accuracy: 0.7294 - val_loss: 1.1054 - val_accuracy: 0.6535\n",
      "Epoch 10/20\n",
      "193/193 [==============================] - 1s 4ms/step - loss: 0.8344 - accuracy: 0.7303 - val_loss: 1.0821 - val_accuracy: 0.6594\n",
      "Epoch 11/20\n",
      "193/193 [==============================] - 2s 9ms/step - loss: 0.8158 - accuracy: 0.7377 - val_loss: 1.1039 - val_accuracy: 0.6637\n",
      "Epoch 12/20\n",
      "193/193 [==============================] - 1s 5ms/step - loss: 0.8087 - accuracy: 0.7465 - val_loss: 1.0842 - val_accuracy: 0.6652\n",
      "Epoch 13/20\n",
      "193/193 [==============================] - 1s 3ms/step - loss: 0.8025 - accuracy: 0.7439 - val_loss: 1.0818 - val_accuracy: 0.6594\n",
      "Epoch 14/20\n",
      "193/193 [==============================] - 1s 4ms/step - loss: 0.7973 - accuracy: 0.7423 - val_loss: 1.0579 - val_accuracy: 0.6681\n",
      "Epoch 15/20\n",
      "193/193 [==============================] - 1s 5ms/step - loss: 0.7885 - accuracy: 0.7473 - val_loss: 1.0888 - val_accuracy: 0.6579\n",
      "Epoch 16/20\n",
      "193/193 [==============================] - 2s 8ms/step - loss: 0.7840 - accuracy: 0.7525 - val_loss: 1.1179 - val_accuracy: 0.6491\n",
      "Epoch 17/20\n",
      "193/193 [==============================] - 1s 4ms/step - loss: 0.7685 - accuracy: 0.7537 - val_loss: 1.1141 - val_accuracy: 0.6608\n",
      "Epoch 18/20\n",
      "193/193 [==============================] - 2s 8ms/step - loss: 0.7705 - accuracy: 0.7528 - val_loss: 1.0677 - val_accuracy: 0.6637\n",
      "Epoch 19/20\n",
      "193/193 [==============================] - 1s 6ms/step - loss: 0.7594 - accuracy: 0.7564 - val_loss: 1.0735 - val_accuracy: 0.6608\n",
      "Epoch 20/20\n",
      "193/193 [==============================] - 1s 5ms/step - loss: 0.7673 - accuracy: 0.7545 - val_loss: 1.0781 - val_accuracy: 0.6652\n",
      "Model: \"sequential_6\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " sequential_5 (Sequential)   (None, 128)               110208    \n",
      "                                                                 \n",
      " dense_8 (Dense)             (None, 64)                8256      \n",
      "                                                                 \n",
      " dense_9 (Dense)             (None, 19)                1235      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 119,699\n",
      "Trainable params: 9,491\n",
      "Non-trainable params: 110,208\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "history3 = new_model.fit(X_train_seq_RA, y_train_seq_RA, epochs = 20, batch_size = 32, validation_split = 0.1, shuffle = True)\n",
    "\n",
    "new_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "992e6047",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "72/72 [==============================] - 0s 4ms/step - loss: 1.1225 - accuracy: 0.6567\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[1.1225109100341797, 0.6567164063453674]"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_model.evaluate(X_test_seq_RA, y_test_seq_RA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5da8aba0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
